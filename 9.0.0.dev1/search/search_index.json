{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Parsedmarc: Open source DMARC report analyzer and visualizer","text":"<p>Danger</p> <p>This is not the official parsedmarc documentation</p> <p>This is a test branch showcasing mkdocs</p> <p>Help Wanted</p> <p>This is a project is maintained by one developer. Please consider reviewing the open issues to see how you can contribute code, documentation, or user support. Assistance on the pinned issues would be particularly helpful.</p> <p>Thanks to all contributors!</p> <p><code>parsedmarc</code> is a Python module and CLI utility for parsing DMARC reports. When used with Elasticsearch and Kibana (or Splunk), it works as a self-hosted open source alternative to commercial DMARC report processing services such as Agari Brand Protection, Dmarcian, OnDMARC, ProofPoint Email Fraud Defense, and Valimail.</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Parses draft and 1.0 standard aggregate/rua reports</li> <li>Parses forensic/failure/ruf reports</li> <li>Can parse reports from an inbox over IMAP, Microsoft Graph, or Gmail API</li> <li>Transparently handles gzip or zip compressed reports</li> <li>Consistent data structures</li> <li>Simple JSON and/or CSV output</li> <li>Optionally email the results</li> <li>Optionally send the results to Elasticsearch and/or Splunk, for use with   premade dashboards</li> <li>Optionally send reports to Apache Kafka</li> </ul>"},{"location":"contributing/","title":"Contributing to parsedmarc","text":""},{"location":"contributing/#bug-reports","title":"Bug reports","text":"<p>Please report bugs on the GitHub issue tracker</p> <p>https://github.com/domainaware/parsedmarc/issues</p>"},{"location":"davmail/","title":"Accessing an inbox using OWA/EWS","text":"<p>Note</p> <p>Starting in 8.0.0, parsedmarc supports accessing Microsoft/Office 365 inboxes via the Microsoft Graph API, which is preferred over Davmail.</p> <p>Some organizations do not allow IMAP or the Microsoft Graph API, and only support Exchange Web Services (EWS)/Outlook Web Access (OWA). In that case, Davmail will need to be set up as a local EWS/OWA IMAP gateway. It can even work where Modern Auth/multi-factor authentication is required.</p> <p>To do this, download the latest <code>davmail-version.zip</code> from https://sourceforge.net/projects/davmail/files/</p> <p>Extract the zip using the <code>unzip</code> command.</p> <p>Install Java:</p> <pre><code>sudo apt-get install default-jre-headless\n</code></pre> <p>Configure Davmail by creating a <code>davmail.properties</code> file</p> <pre><code># DavMail settings, see http://davmail.sourceforge.net/ for documentation\n\n#############################################################\n# Basic settings\n\n# Server or workstation mode\ndavmail.server=true\n\n# connection mode auto, EWS or WebDav\ndavmail.enableEws=auto\n\n# base Exchange OWA or EWS url\ndavmail.url=https://outlook.office365.com/EWS/Exchange.asmx\n\n# Listener ports\ndavmail.imapPort=1143\n\n#############################################################\n# Network settings\n\n# Network proxy settings\ndavmail.enableProxy=false\ndavmail.useSystemProxies=false\ndavmail.proxyHost=\ndavmail.proxyPort=\ndavmail.proxyUser=\ndavmail.proxyPassword=\n\n# proxy exclude list\ndavmail.noProxyFor=\n\n# block remote connection to DavMail\ndavmail.allowRemote=false\n\n# bind server sockets to the loopback address\ndavmail.bindAddress=127.0.0.1\n\n# disable SSL for specified listeners\ndavmail.ssl.nosecureimap=true\n\n# Send keepalive character during large folder and messages download\ndavmail.enableKeepalive=true\n\n# Message count limit on folder retrieval\ndavmail.folderSizeLimit=0\n\n#############################################################\n# IMAP settings\n\n# Delete messages immediately on IMAP STORE \\Deleted flag\ndavmail.imapAutoExpunge=true\n\n# Enable IDLE support, set polling delay in minutes\ndavmail.imapIdleDelay=1\n\n# Always reply to IMAP RFC822.SIZE requests with Exchange approximate\n# message size for performance reasons\ndavmail.imapAlwaysApproxMsgSize=true\n\n# Client connection timeout in seconds - default 300, 0 to disable\ndavmail.clientSoTimeout=0\n\n#############################################################\n</code></pre>"},{"location":"davmail/#running-davmail-as-a-systemd-service","title":"Running DavMail as a systemd service","text":"<p>Use systemd to run <code>davmail</code> as a service.</p> <p>Create a system user</p> <pre><code>sudo useradd davmail -r -s /bin/false\n</code></pre> <p>Protect the <code>davmail</code> configuration file from prying eyes</p> <pre><code>sudo chown root:davmail /opt/davmail/davmail.properties\nsudo chmod u=rw,g=r,o= /opt/davmail/davmail.properties\n</code></pre> <p>Create the service configuration file</p> <pre><code>sudo nano /etc/systemd/system/davmail.service\n</code></pre> <pre><code>[Unit]\nDescription=DavMail gateway service\nDocumentation=https://sourceforge.net/projects/davmail/\nWants=network-online.target\nAfter=syslog.target network.target\n\n[Service]\nExecStart=/opt/davmail/davmail /opt/davmail/davmail.properties\nUser=davmail\nGroup=davmail\nRestart=always\nRestartSec=5m\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Then, enable the service</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable parsedmarc.service\nsudo service davmail restart\n</code></pre> <p>Note</p> <p>You must also run the above commands whenever you edit <code>davmail.service</code>.</p> <p>Warning</p> <p>Always restart the service every time you upgrade to a new version of <code>davmail</code>:</p> <pre><code>sudo service davmail restart\n</code></pre> <p>To check the status of the service, run:</p> <pre><code>service davmail status\n</code></pre> <p>Note</p> <p>In the event of a crash, systemd will restart the service after 5 minutes, but the <code>service davmail status</code> command will only show the logs for the current process. To vew the logs for previous runs as well as the current process (newest to oldest), run:</p> <pre><code>journalctl -u davmail.service -r\n</code></pre>"},{"location":"davmail/#configuring-parsedmarc-for-davmail","title":"Configuring parsedmarc for DavMail","text":"<p>Because you are interacting with DavMail server over the loopback (i.e. <code>127.0.0.1</code>), add the following options to <code>parsedmarc.ini</code> config file:</p> <pre><code>[imap]\nhost=127.0.0.1\nport=1143\nssl=False\nwatch=True\n</code></pre>"},{"location":"dmarc/","title":"Understanding DMARC","text":""},{"location":"dmarc/#resources","title":"Resources","text":""},{"location":"dmarc/#dmarc-guides","title":"DMARC guides","text":"<ul> <li>Demystifying DMARC - A complete guide to SPF, DKIM, and DMARC</li> </ul>"},{"location":"dmarc/#spf-and-dmarc-record-validation","title":"SPF and DMARC record validation","text":"<p>If you are looking for SPF and DMARC record validation and parsing, check out the sister project, checkdmarc.</p>"},{"location":"dmarc/#lookalike-domains","title":"Lookalike domains","text":"<p>DMARC protects against domain spoofing, not lookalike domains. for open source lookalike domain monitoring, check out DomainAware.</p>"},{"location":"dmarc/#dmarc-alignment-guide","title":"DMARC Alignment Guide","text":"<p>DMARC ensures that SPF and DKM authentication mechanisms actually authenticate against the same domain that the end user sees.</p> <p>A message passes a DMARC check by passing DKIM or SPF, as long as the related indicators are also in alignment.</p> <pre><code>+-----------------------+-----------------------+-----------------------+\n|                       | **DKIM**              | **SPF**               |\n+-----------------------+-----------------------+-----------------------+\n| **Passing**           | The signature in the  | The mail server's IP  |\n|                       | DKIM header is        | address is listed in  |\n|                       | validated using a     | the SPF record of the |\n|                       | public key that is    | domain in the SMTP    |\n|                       | published as a DNS    | envelope's mail from  |\n|                       | record of the domain  | header                |\n|                       | name specified in the |                       |\n|                       | signature             |                       |\n+-----------------------+-----------------------+-----------------------+\n| **Alignment**         | The signing domain    | The domain in the     |\n|                       | aligns with the       | SMTP envelope's mail  |\n|                       | domain in the         | from header aligns    |\n|                       | message's from header | with the domain in    |\n|                       |                       | the message's from    |\n|                       |                       | header                |\n+-----------------------+-----------------------+-----------------------+\n</code></pre>"},{"location":"dmarc/#what-if-a-sender-wont-support-dkimdmarc","title":"What if a sender won't support DKIM/DMARC?","text":"<ol> <li>Some vendors don't know about DMARC yet; ask about SPF and DKIM/email    authentication.</li> <li>Check if they can send through your email relays instead of theirs.</li> <li>Do they really need to spoof your domain? Why not use the display    name instead?</li> <li>Worst case, have that vendor send email as a specific subdomain of    your domain (e.g. <code>noreply@news.example.com</code>), and then create    separate SPF and DMARC records on <code>news.example.com</code>, and set    <code>p=none</code> in that DMARC record.</li> </ol> <p>Warning</p> <p>Do not alter the <code>p</code> or <code>sp</code> values of the DMARC record on the Top-Level Domain (TLD) \u2013 that would leave you vulnerable to spoofing of your TLD and/or any subdomain.</p>"},{"location":"elasticsearch/","title":"Elasticsearch and Kibana","text":"<p>To set up visual dashboards of DMARC data, install Elasticsearch and Kibana.</p> <p>Note</p> <p>Elasticsearch and Kibana 6 or later are required</p>"},{"location":"elasticsearch/#installation","title":"Installation","text":"<p>On Debian/Ubuntu based systems, run:</p> <pre><code>sudo apt-get install -y apt-transport-https\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main\" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list\nsudo apt-get update\nsudo apt-get install -y elasticsearch kibana\n</code></pre> <p>For CentOS, RHEL, and other RPM systems, follow the Elastic RPM guides for Elasticsearch and Kibana.</p> <p>Note</p> <p>Previously, the default JVM heap size for Elasticsearch was very small (1g), which will cause it to crash under a heavy load. To fix this, increase the minimum and maximum JVM heap sizes in <code>/etc/elasticsearch/jvm.options</code> to more reasonable levels, depending on your server's resources.</p> <p>Make sure the system has at least 2 GB more RAM than the assigned JVM heap size.</p> <p>Always set the minimum and maximum JVM heap sizes to the same value.</p> <p>For example, to set a 4 GB heap size, set</p> <pre><code>-Xms4g\n-Xmx4g\n</code></pre> <p>See https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html#heap-size-settings for more information.</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable elasticsearch.service\nsudo systemctl enable kibana.service\nsudo service elasticsearch start\nsudo service kibana start\n</code></pre> <p>As of Elasticsearch 8.7, activate secure mode (xpack.security.*.ssl)</p> <pre><code>sudo vim /etc/elasticsearch/elasticsearch.yml\n</code></pre> <p>Add the following configuration</p> <pre><code># Enable security features\nxpack.security.enabled: true\nxpack.security.enrollment.enabled: true\n# Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents\nxpack.security.http.ssl:\n  enabled: true\n  keystore.path: certs/http.p12\n# Enable encryption and mutual authentication between cluster nodes\nxpack.security.transport.ssl:\n  enabled: true\n  verification_mode: certificate\n  keystore.path: certs/transport.p12\n  truststore.path: certs/transport.p12\n</code></pre> <pre><code>sudo systemctl restart elasticsearch\n</code></pre> <p>To create a self-signed certificate, run:</p> <pre><code>openssl req -x509 -nodes -days 365 -newkey rsa:4096 -keyout kibana.key -out kibana.crt\n</code></pre> <p>Or, to create a Certificate Signing Request (CSR) for a CA, run:</p> <pre><code>openssl req -newkey rsa:4096-nodes -keyout kibana.key -out kibana.csr\n</code></pre> <p>Fill in the prompts. Watch out for Common Name (e.g. server FQDN or YOUR domain name), which is the IP address or domain name that you will use to access Kibana. it is the most important field.</p> <p>If you generated a CSR, remove the CSR after you have your certs</p> <pre><code>rm -f kibana.csr\n</code></pre> <p>Move the keys into place and secure them:</p> <pre><code>sudo mv kibana.* /etc/kibana\nsudo chmod 660 /etc/kibana/kibana.key\n</code></pre> <p>Activate the HTTPS server in Kibana</p> <pre><code>sudo vim /etc/kibana/kibana.yml\n</code></pre> <p>Add the following configuration</p> <pre><code>server.host: \"SERVER_IP\"\nserver.publicBaseUrl: \"https://SERVER_IP\"\nserver.ssl.enabled: true\nserver.ssl.certificate: /etc/kibana/kibana.crt\nserver.ssl.key: /etc/kibana/kibana.key\n</code></pre> <p>Note</p> <p>For more security, you can configure Kibana to use a local network connexion to elasticsearch : <pre><code>elasticsearch.hosts: ['https://SERVER_IP:9200']\n</code></pre> =&gt;  <pre><code>elasticsearch.hosts: ['https://127.0.0.1:9200']\n</code></pre></p> <pre><code>sudo systemctl restart kibana\n</code></pre> <p>Enroll Kibana in Elasticsearch</p> <pre><code>sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\n</code></pre> <p>Then access to your web server at <code>https://SERVER_IP:5601</code>, accept the self-signed certificate and paste the token in the \"Enrollment token\" field.</p> <pre><code>sudo /usr/share/kibana/bin/kibana-verification-code\n</code></pre> <p>Then put the verification code to your web browser.</p> <p>End Kibana configuration</p> <pre><code>sudo /usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive\nsudo /usr/share/kibana/bin/kibana-encryption-keys generate\nsudo vim /etc/kibana/kibana.yml\n</code></pre> <p>Add previously generated encryption keys</p> <pre><code>xpack.encryptedSavedObjects.encryptionKey: xxxx...xxxx\nxpack.reporting.encryptionKey: xxxx...xxxx\nxpack.security.encryptionKey: xxxx...xxxx\n</code></pre> <pre><code>sudo systemctl restart kibana\nsudo systemctl restart elasticsearch\n</code></pre> <p>Now that Elasticsearch is up and running, use <code>parsedmarc</code> to send data to it.</p> <p>Download (right-click the link and click save as) export.ndjson.</p> <p>Connect to kibana using the \"elastic\" user and the password you previously provide on the console (\"End Kibana configuration\" part).</p> <p>Import <code>export.ndjson</code> the Saved Objects tab of the Stack management page of Kibana. (Hamburger menu -&gt; \"Management\" -&gt; \"Stack Management\" -&gt; \"Kibana\" -&gt; \"Saved Objects\")</p> <p>It will give you the option to overwrite existing saved dashboards or visualizations, which could be used to restore them if you or someone else breaks them, as there are no permissions/access controls in Kibana without the commercial X-Pack.</p> <p> </p>"},{"location":"elasticsearch/#upgrading-kibana-index-patterns","title":"Upgrading Kibana index patterns","text":"<p><code>parsedmarc</code> 5.0.0 makes some changes to the way data is indexed in Elasticsearch. if you are upgrading from a previous release of <code>parsedmarc</code>, you need to complete the following steps to replace the Kibana index patterns with versions that match the upgraded indexes:</p> <ol> <li>Login in to Kibana, and click on Management</li> <li>Under Kibana, click on Saved Objects</li> <li>Check the checkboxes for the <code>dmarc_aggregate</code> and <code>dmarc_forensic</code>    index patterns</li> <li>Click Delete</li> <li>Click Delete on the conformation message</li> <li>Download (right-click the link and click save as)    the latest version of export.ndjson</li> <li>Import <code>export.ndjson</code> by clicking Import from the Kibana    Saved Objects page</li> </ol>"},{"location":"elasticsearch/#records-retention","title":"Records retention","text":"<p>Starting in version 5.0.0, <code>parsedmarc</code> stores data in a separate index for each day to make it easy to comply with records retention regulations such as GDPR. For more information, check out the Elastic guide to managing time-based indexes efficiently.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p><code>parsedmarc</code> works with Python 3 only.</p>"},{"location":"installation/#testing-multiple-report-analyzers","title":"Testing multiple report analyzers","text":"<p>If you would like to test parsedmarc and another report processing solution at the same time, you can have up to two <code>mailto</code> URIs in each of the rua and ruf tags in your DMARC record, separated by commas.</p>"},{"location":"installation/#using-a-web-proxy","title":"Using a web proxy","text":"<p>If your system is behind a web proxy, you need to configure your system to use that proxy. To do this, edit <code>/etc/environment</code> and add your proxy details there, for example:</p> <pre><code>http_proxy=http://user:password@prox-server:3128\nhttps_proxy=https://user:password@prox-server:3128\nftp_proxy=http://user:password@prox-server:3128\n</code></pre> <p>Or if no credentials are needed:</p> <pre><code>http_proxy=http://prox-server:3128\nhttps_proxy=https://prox-server:3128\nftp_proxy=http://prox-server:3128\n</code></pre> <p>This will set the proxy up for use system-wide, including for <code>parsedmarc</code>.</p>"},{"location":"installation/#using-microsoft-exchange","title":"Using Microsoft Exchange","text":"<p>If your mail server is Microsoft Exchange, ensure that it is patched to at least:</p> <ul> <li>Exchange Server 2010 Update Rollup 22 (KB4295699)</li> <li>Exchange Server 2013 Cumulative Update 21 (KB4099855)</li> <li>Exchange Server 2016 Cumulative Update 11 (KB4134118)</li> </ul>"},{"location":"installation/#geoipupdate-setup","title":"geoipupdate setup","text":"<p>Note</p> <p>Starting in <code>parsedmarc</code> 7.1.0, a static copy of the IP to Country Lite database from IPDB is distributed with <code>parsedmarc</code>, under the terms of the [Creative Commons Attribution 4.0 International License] as a fallback if the MaxMind GeoLite2 Country database is not installed. However, <code>parsedmarc</code> cannot install updated versions of these databases as they are released, so MaxMind's databases and the geoipupdate tool is still the preferable solution.</p> <p>The location of the database file can be overridden by using the <code>ip_db_path</code> setting.</p> <p>On Debian 10 (Buster) or later, run:</p> <pre><code>sudo apt-get install -y geoipupdate\n</code></pre> <p>Note</p> <p>Component \"contrib\" is required in your apt sources.</p> <p>On Ubuntu systems run:</p> <pre><code>sudo add-apt-repository ppa:maxmind/ppa\nsudo apt update\nsudo apt install -y geoipupdate\n</code></pre> <p>On CentOS or RHEL systems, run:</p> <pre><code>sudo dnf install -y geoipupdate\n</code></pre> <p>The latest builds for Linux, macOS, and Windows can be downloaded from the geoipupdate releases page on GitHub.</p> <p>On December 30th, 2019, MaxMind started requiring free accounts to access the free Geolite2 databases, in order  to comply with various privacy regulations.</p> <p>Start by registering for a free GeoLite2 account, and signing in.</p> <p>Then, navigate to the License Keys page under your account, and create a new license key for the version of <code>geoipupdate</code> that was installed.</p> <p>Warning</p> <p>The configuration file format is different for older (i.e. \\&lt;=3.1.1) and newer (i.e. &gt;=3.1.1) versions of <code>geoipupdate</code>. Be sure to select the correct version for your system.</p> <p>Note</p> <p>To check the version of <code>geoipupdate</code> that is installed, run:</p> <pre><code>geoipupdate -V\n</code></pre> <p>You can use <code>parsedmarc</code> as the description for the key.</p> <p>Once you have generated a key, download the config pre-filled configuration file. This file should be saved at <code>/etc/GeoIP.conf</code> on Linux or macOS systems, or at <code>%SystemDrive%\\ProgramData\\MaxMind\\GeoIPUpdate\\GeoIP.conf</code> on Windows systems.</p> <p>Then run</p> <pre><code>sudo geoipupdate\n</code></pre> <p>To download the databases for the first time.</p> <p>The GeoLite2 Country, City, and ASN databases are updated weekly, every Tuesday. <code>geoipupdate</code> can be run weekly by adding a cron job or scheduled task.</p> <p>More information about <code>geoipupdate</code> can be found at the MaxMind geoipupdate page.</p>"},{"location":"installation/#installing-parsedmarc","title":"Installing parsedmarc","text":"<p>On Debian or Ubuntu systems, run:</p> <pre><code>sudo apt-get install -y python3-pip python3-virtualenv python3-dev libxml2-dev libxslt-dev\n</code></pre> <p>On CentOS or RHEL systems, run:</p> <pre><code>sudo dnf install -y python39 python3-virtualenv python3-setuptools python3-devel libxml2-devel libxslt-devel\n</code></pre> <p>Python 3 installers for Windows and macOS can be found at https://www.python.org/downloads/.</p> <p>Create a system user</p> <pre><code>sudo mkdir /opt\nsudo useradd parsedmarc -r -s /bin/false -m -b /opt\n</code></pre> <p>Install parsedmarc in a virtualenv</p> <pre><code>sudo -u parsedmarc virtualenv /opt/parsedmarc/venv\n</code></pre> <p>CentOS/RHEL 8 systems use Python 3.6 by default, so on those systems explicitly tell <code>virtualenv</code> to use <code>python3.9</code> instead</p> <pre><code>sudo -u parsedmarc virtualenv -p python3.9  /opt/parsedmarc/venv\n</code></pre> <p>Activate the virtualenv</p> <pre><code>source /opt/parsedmarc/venv/bin/activate\n</code></pre> <p>To install or upgrade <code>parsedmarc</code> inside the virtualenv, run:</p> <pre><code>sudo -u parsedmarc /opt/parsedmarc/venv/bin/pip install -U parsedmarc\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional dependencies","text":"<p>If you would like to be able to parse emails saved from Microsoft Outlook (i.e. OLE .msg files), install <code>msgconvert</code>:</p> <p>On Debian or Ubuntu systems, run:</p> <pre><code>sudo apt-get install libemail-outlook-message-perl\n</code></pre>"},{"location":"kibana/","title":"Using the Kibana dashboards","text":"<p>The Kibana DMARC dashboards are a human-friendly way to understand the results from incoming DMARC reports.</p> <p>Note</p> <p>The default dashboard is DMARC Summary. To switch between dashboards, click on the Dashboard link on the left side menu of Kibana.</p>"},{"location":"kibana/#dmarc-summary","title":"DMARC Summary","text":"<p>As the name suggests, this dashboard is the best place to start reviewing your aggregate DMARC data.</p> <p>Across the top of the dashboard, three pie charts display the percentage of alignment pass/fail for SPF, DKIM, and DMARC. Clicking on any chart segment will filter for that value.</p> <p>Note</p> <p>Messages should not be considered malicious just because they failed to pass DMARC; especially if you have just started collecting data. It may be a legitimate service that needs SPF and DKIM configured correctly.</p> <p>Start by filtering the results to only show failed DKIM alignment. While DMARC passes if a message passes SPF or DKIM alignment, only DKIM alignment remains valid when a message is forwarded without changing the from address, which is often caused by a mailbox forwarding rule. This is because DKIM signatures are part of the message headers, whereas SPF relies on SMTP session headers.</p> <p>Underneath the pie charts. you can see graphs of DMARC passage and message disposition over time.</p> <p>Under the graphs you will find the most useful data tables on the dashboard. On the left, there is a list of organizations that are sending you DMARC reports. In the center, there is a list of sending servers grouped by the base domain in their reverse DNS. On the right, there is a list of email from domains, sorted by message volume.</p> <p>By hovering your mouse over a data table value and using the magnifying glass icons, you can filter on our filter out different values. Start by looking at the Message Sources by Reverse DNS table. Find a sender that you recognize, such as an email marketing service, hover over it, and click on the plus (+) magnifying glass icon, to add a filter that only shows results for that sender. Now, look at the Message From Header table to the right. That shows you the domains that a sender is sending as, which might tell you which brand/business is using a particular service. With that information, you can contact them and have them set up DKIM.</p> <p>Note</p> <p>If you have a lot of B2C customers, you may see a high volume of emails as your domains coming from consumer email services, such as Google/Gmail and Yahoo! This occurs when customers have mailbox rules in place that forward emails from an old account to a new account, which is why DKIM authentication is so important, as mentioned earlier. Similar patterns may be observed with businesses who send from reverse DNS addressees of parent, subsidiary, and outdated brands.</p> <p>Further down the dashboard, you can filter by source country or source IP address.</p> <p>Tables showing SPF and DKIM alignment details are located under the IP address table.</p> <p>Note</p> <p>Previously, the alignment tables were included in a separate dashboard called DMARC Alignment Failures. That dashboard has been consolidated into the DMARC Summary dashboard. To view failures only, use the pie chart.</p> <p>Any other filters work the same way. You can also add your own custom temporary filters by clicking on Add Filter at the upper right of the page.</p>"},{"location":"kibana/#dmarc-forensic-samples","title":"DMARC Forensic Samples","text":"<p>The DMARC Forensic Samples dashboard contains information on DMARC forensic reports (also known as failure reports or ruf reports). These reports contain samples of emails that have failed to pass DMARC.</p> <p>Note</p> <p>Most recipients do not send forensic/failure/ruf reports at all to avoid privacy leaks. Some recipients (notably Chinese webmail services) will only supply the headers of sample emails. Very few provide the entire email.</p>"},{"location":"mailing-lists/","title":"DMARC and Mailing Lists","text":"<p>When you deploy DMARC on your domain, you might find that messages relayed by mailing lists are failing DMARC, most likely because the mailing list is spoofing your from address, and modifying the subject, footer, or other part of the message, thereby breaking the DKIM signature.</p>"},{"location":"mailing-lists/#mailing-list-best-practices","title":"Mailing list best practices","text":"<p>Ideally, a mailing list should forward messages without altering the headers or body content at all. Joe Nelson does a fantastic job of explaining exactly what mailing lists should and shouldn't do to be fully DMARC compliant. Rather than repeat his fine work, here's a summary:</p> <p>Do</p> <ul> <li>Retain headers from the original message</li> </ul> <ul> <li> <p>Add RFC 2369 List-Unsubscribe headers to outgoing messages, instead of   adding unsubscribe links to the body</p> <p>List-Unsubscribe: https://list.example.com/unsubscribe-link</p> </li> </ul> <ul> <li> <p>Add RFC 2919 List-Id headers instead of modifying the subject</p> <p>List-Id: Example Mailing List  <p>Modern mail clients and webmail services generate unsubscribe buttons based on these headers.</p> <p>Do Not</p> <ul> <li>Remove or modify any existing headers from the original message, including From, Date, Subject, etc.</li> <li>Add to or remove content from the message body, including traditional disclaimers and unsubscribe footers</li> </ul> <p>In addition to complying with DMARC, this configuration ensures that Reply and Reply All actions work like they would with any email message. Reply replies to the message sender, and Reply All replies to the sender and the list.</p> <p>Even without a subject prefix or body footer, mailing list users can still tell that a message came from the mailing list, because the message was sent to the mailing list post address, and not their email address.</p>"},{"location":"mailing-lists/#configuring-common-platforms","title":"Configuring common platforms","text":"<p>Configuration steps for common mailing list platforms are listed below.</p>"},{"location":"mailing-lists/#mailman-2","title":"Mailman 2","text":"<ol> <li> <p>Navigate to General Settings, and configure the settings below</p> Setting Value <code>subject_prefix</code> <code>from_is_list</code> No <code>first_strip_reply_to</code> No <code>reply_goes_to_list</code> Poster <code>include_rfc2369_headers</code> Yes <code>include_list_post_header</code> Yes <code>include_sender_header</code> No </li> <li> <p>Navigate to Non-digest options, and configure the settings below</p> Setting Value <code>msg_header</code> <code>msg_footer</code> <code>scrub_nondigest</code> No </li> <li> <p>Navigate to Privacy Options &gt; Sending Filters, and configure the settings below</p> Setting Value <code>dmarc_moderation_action</code> Accept <code>dmarc_quarantine_moderation_action</code> Yes <code>dmarc_none_moderation_action</code> Yes </li> </ol>"},{"location":"mailing-lists/#mailman-3","title":"Mailman 3","text":"<ol> <li> <p>Navigate to Settings&gt; List Identity</p> <p>Make Subject prefix blank.</p> </li> <li> <p>Navigate to Settings&gt; Alter Messages</p> <p>Configure the settings below</p> Setting Value Convert html to plaintext No Include RFC2369 headers Yes Include the list post header Yes Explicit reply-to address First strip replyto No Reply goes to list No munging </li> <li> <p>Navigate to Settings&gt; DMARC Mitigation</p> <p>Configure the settings below</p> Setting Value DMARC mitigation action No DMARC mitigations DMARC mitigate unconditionally No </li> <li> <p>Create a blank footer template for your mailing list to remove the message footer.</p> <p>Unfortunately, the Postorius mailing list admin UI will not allow you   to create an empty template, so you'll have to create one using the system's   command line instead, for example:</p> <pre><code>touch var/templates/lists/list.example.com/en/list:member:regular:footer\n</code></pre> <p>Where <code>list.example.com</code> the list ID, and <code>en</code> is the language.</p> </li> <li> <p>Restart mailman core.</p> </li> </ol>"},{"location":"mailing-lists/#listserv","title":"LISTSERV","text":"<p>LISTSERV 16.0-2017a and higher will rewrite the From header for domains that enforce with a DMARC quarantine or reject policy.</p> <p>Some additional steps are needed for Linux hosts.</p>"},{"location":"mailing-lists/#workarounds","title":"Workarounds","text":"<p>If a mailing list must go against best practices and modify the message (e.g. to add a required legal footer), the mailing list administrator must configure the list to replace the From address of the message (also known as munging) with the address of the mailing list, so they no longer spoof email addresses with domains protected by DMARC.</p> <p>Configuration steps for common mailing list platforms are listed below.</p>"},{"location":"mailing-lists/#mailman-2_1","title":"Mailman 2","text":"<ol> <li>Navigate to Privacy Options&gt; Sending Filters and configure the settings below Setting Value <code>dmarc_moderation_action</code> Munge From <code>dmarc_quarantine_moderation_action</code> Yes <code>dmarc_none_moderation_action</code> Yes </li> </ol> <p>Note</p> <p>Message wrapping could be used as the DMARC mitigation action instead. In that case, the original message is added as an attachment to the mailing list message, but that could interfere with inbox searching, or mobile clients.</p> <p>On the other hand, replacing the From address might cause users to accidentally reply to the entire list, when they only intended to reply to the original sender.</p> <p>Choose the option that best fits your community.</p>"},{"location":"mailing-lists/#mailman-3_1","title":"Mailman 3","text":"<ol> <li>Navigate to Settings &gt; DMARC Mitigations and configure the settings below Setting Value DMARC mitigation action Replace From: with list address DMARC mitigate unconditionally No </li> </ol> <p>Note</p> <p>Message wrapping could be used as the DMARC mitigation action instead. In that case, the original message is added as an attachment to the mailing list message, but that could interfere with inbox searching, or mobile clients.</p> <p>On the other hand, replacing the From address might cause users to accidentally reply to the entire list, when they only intended to reply to the original sender.</p>"},{"location":"output/","title":"Sample outputs","text":""},{"location":"output/#sample-aggregate-report-output","title":"Sample aggregate report output","text":"<p>Here are the results from parsing the example report from the dmarc.org wiki. It's actually an older draft of the 1.0 report schema standardized in RFC 7480 Appendix C. This draft schema is still in wide use.</p> <p><code>parsedmarc</code> produces consistent, normalized output, regardless of the report schema.</p>"},{"location":"output/#json-aggregate-report","title":"JSON aggregate report","text":"<pre><code>{\n  \"xml_schema\": \"draft\",\n  \"report_metadata\": {\n    \"org_name\": \"acme.com\",\n    \"org_email\": \"noreply-dmarc-support@acme.com\",\n    \"org_extra_contact_info\": \"http://acme.com/dmarc/support\",\n    \"report_id\": \"9391651994964116463\",\n    \"begin_date\": \"2012-04-27 20:00:00\",\n    \"end_date\": \"2012-04-28 19:59:59\",\n    \"errors\": []\n  },\n  \"policy_published\": {\n    \"domain\": \"example.com\",\n    \"adkim\": \"r\",\n    \"aspf\": \"r\",\n    \"p\": \"none\",\n    \"sp\": \"none\",\n    \"pct\": \"100\",\n    \"fo\": \"0\"\n  },\n  \"records\": [\n    {\n      \"source\": {\n        \"ip_address\": \"72.150.241.94\",\n        \"country\": \"US\",\n        \"reverse_dns\": \"adsl-72-150-241-94.shv.bellsouth.net\",\n        \"base_domain\": \"bellsouth.net\"\n      },\n      \"count\": 2,\n      \"alignment\": {\n        \"spf\": true,\n        \"dkim\": false,\n        \"dmarc\": true\n      },\n      \"policy_evaluated\": {\n        \"disposition\": \"none\",\n        \"dkim\": \"fail\",\n        \"spf\": \"pass\",\n        \"policy_override_reasons\": []\n      },\n      \"identifiers\": {\n        \"header_from\": \"example.com\",\n        \"envelope_from\": \"example.com\",\n        \"envelope_to\": null\n      },\n      \"auth_results\": {\n        \"dkim\": [\n          {\n            \"domain\": \"example.com\",\n            \"selector\": \"none\",\n            \"result\": \"fail\"\n          }\n        ],\n        \"spf\": [\n          {\n            \"domain\": \"example.com\",\n            \"scope\": \"mfrom\",\n            \"result\": \"pass\"\n          }\n        ]\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"output/#csv-aggregate-report","title":"CSV aggregate report","text":"<pre><code>xml_schema,org_name,org_email,org_extra_contact_info,report_id,begin_date,end_date,errors,domain,adkim,aspf,p,sp,pct,fo,source_ip_address,source_country,source_reverse_dns,source_base_domain,count,spf_aligned,dkim_aligned,dmarc_aligned,disposition,policy_override_reasons,policy_override_comments,envelope_from,header_from,envelope_to,dkim_domains,dkim_selectors,dkim_results,spf_domains,spf_scopes,spf_results\ndraft,acme.com,noreply-dmarc-support@acme.com,http://acme.com/dmarc/support,9391651994964116463,2012-04-27 20:00:00,2012-04-28 19:59:59,,example.com,r,r,none,none,100,0,72.150.241.94,US,adsl-72-150-241-94.shv.bellsouth.net,bellsouth.net,2,True,False,True,none,,,example.com,example.com,,example.com,none,fail,example.com,mfrom,pass\n</code></pre>"},{"location":"output/#sample-forensic-report-output","title":"Sample forensic report output","text":"<p>Thanks to GitHub user xennn for the anonymized forensic report email sample.</p>"},{"location":"output/#json-forensic-report","title":"JSON forensic report","text":"<pre><code>{\n     \"feedback_type\": \"auth-failure\",\n     \"user_agent\": \"Lua/1.0\",\n     \"version\": \"1.0\",\n     \"original_mail_from\": \"sharepoint@domain.de\",\n     \"original_rcpt_to\": \"peter.pan@domain.de\",\n     \"arrival_date\": \"Mon, 01 Oct 2018 11:20:27 +0200\",\n     \"message_id\": \"&lt;38.E7.30937.BD6E1BB5@ mailrelay.de&gt;\",\n     \"authentication_results\": \"dmarc=fail (p=none, dis=none) header.from=domain.de\",\n     \"delivery_result\": \"policy\",\n     \"auth_failure\": [\n       \"dmarc\"\n     ],\n     \"reported_domain\": \"domain.de\",\n     \"arrival_date_utc\": \"2018-10-01 09:20:27\",\n     \"source\": {\n       \"ip_address\": \"10.10.10.10\",\n       \"country\": null,\n       \"reverse_dns\": null,\n       \"base_domain\": null\n     },\n     \"authentication_mechanisms\": [],\n     \"original_envelope_id\": null,\n     \"dkim_domain\": null,\n     \"sample_headers_only\": false,\n     \"sample\": \"Received: from Servernameone.domain.local (Servernameone.domain.local [10.10.10.10])\\n\\tby  mailrelay.de (mail.DOMAIN.de) with SMTP id 38.E7.30937.BD6E1BB5; Mon,  1 Oct 2018 11:20:27 +0200 (CEST)\\nDate: 01 Oct 2018 11:20:27 +0200\\nMessage-ID: &lt;38.E7.30937.BD6E1BB5@ mailrelay.de&gt;\\nTo: &lt;peter.pan@domain.de&gt;\\nfrom: \\\"=?utf-8?B?SW50ZXJha3RpdmUgV2V0dGJld2VyYmVyLcOcYmVyc2ljaHQ=?=\\\" &lt;sharepoint@domain.de&gt;\\nSubject: Subject\\nMIME-Version: 1.0\\nX-Mailer: Microsoft SharePoint Foundation 2010\\nContent-Type: text/html; charset=utf-8\\nContent-Transfer-Encoding: quoted-printable\\n\\n&lt;html&gt;&lt;head&gt;&lt;base href=3D'\\nwettbewerb' /&gt;&lt;/head&gt;&lt;body&gt;&lt;!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 3.2//EN\\\"=\\n&gt;&lt;HTML&gt;&lt;HEAD&gt;&lt;META NAME=3D\\\"Generator\\\" CONTENT=3D\\\"MS Exchange Server version=\\n 08.01.0240.003\\\"&gt;&lt;/html&gt;\\n\",\n     \"parsed_sample\": {\n       \"from\": {\n         \"display_name\": \"Interaktive Wettbewerber-\u00dcbersicht\",\n         \"address\": \"sharepoint@domain.de\",\n         \"local\": \"sharepoint\",\n         \"domain\": \"domain.de\"\n       },\n       \"to_domains\": [\n         \"domain.de\"\n       ],\n       \"to\": [\n         {\n           \"display_name\": null,\n           \"address\": \"peter.pan@domain.de\",\n           \"local\": \"peter.pan\",\n           \"domain\": \"domain.de\"\n         }\n       ],\n       \"subject\": \"Subject\",\n       \"timezone\": \"+2\",\n       \"mime-version\": \"1.0\",\n       \"date\": \"2018-10-01 09:20:27\",\n       \"content-type\": \"text/html; charset=utf-8\",\n       \"x-mailer\": \"Microsoft SharePoint Foundation 2010\",\n       \"body\": \"&lt;html&gt;&lt;head&gt;&lt;base href='\\nwettbewerb' /&gt;&lt;/head&gt;&lt;body&gt;&lt;!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 3.2//EN\\\"&gt;&lt;HTML&gt;&lt;HEAD&gt;&lt;META NAME=\\\"Generator\\\" CONTENT=\\\"MS Exchange Server version 08.01.0240.003\\\"&gt;&lt;/html&gt;\",\n       \"received\": [\n         {\n           \"from\": \"Servernameone.domain.local Servernameone.domain.local 10.10.10.10\",\n           \"by\": \"mailrelay.de mail.DOMAIN.de\",\n           \"with\": \"SMTP id 38.E7.30937.BD6E1BB5\",\n           \"date\": \"Mon, 1 Oct 2018 11:20:27 +0200 CEST\",\n           \"hop\": 1,\n           \"date_utc\": \"2018-10-01 09:20:27\",\n           \"delay\": 0\n         }\n       ],\n       \"content-transfer-encoding\": \"quoted-printable\",\n       \"message-id\": \"&lt;38.E7.30937.BD6E1BB5@ mailrelay.de&gt;\",\n       \"has_defects\": false,\n       \"headers\": {\n         \"Received\": \"from Servernameone.domain.local (Servernameone.domain.local [10.10.10.10])\\n\\tby  mailrelay.de (mail.DOMAIN.de) with SMTP id 38.E7.30937.BD6E1BB5; Mon,  1 Oct 2018 11:20:27 +0200 (CEST)\",\n         \"Date\": \"01 Oct 2018 11:20:27 +0200\",\n         \"Message-ID\": \"&lt;38.E7.30937.BD6E1BB5@ mailrelay.de&gt;\",\n         \"To\": \"&lt;peter.pan@domain.de&gt;\",\n         \"from\": \"\\\"Interaktive Wettbewerber-\u00dcbersicht\\\" &lt;sharepoint@domain.de&gt;\",\n         \"Subject\": \"Subject\",\n         \"MIME-Version\": \"1.0\",\n         \"X-Mailer\": \"Microsoft SharePoint Foundation 2010\",\n         \"Content-Type\": \"text/html; charset=utf-8\",\n         \"Content-Transfer-Encoding\": \"quoted-printable\"\n       },\n       \"reply_to\": [],\n       \"cc\": [],\n       \"bcc\": [],\n       \"attachments\": [],\n       \"filename_safe_subject\": \"Subject\"\n     }\n   }\n</code></pre>"},{"location":"output/#csv-forensic-report","title":"CSV forensic report","text":"<pre><code>feedback_type,user_agent,version,original_envelope_id,original_mail_from,original_rcpt_to,arrival_date,arrival_date_utc,subject,message_id,authentication_results,dkim_domain,source_ip_address,source_country,source_reverse_dns,source_base_domain,delivery_result,auth_failure,reported_domain,authentication_mechanisms,sample_headers_only\nauth-failure,Lua/1.0,1.0,,sharepoint@domain.de,peter.pan@domain.de,\"Mon, 01 Oct 2018 11:20:27 +0200\",2018-10-01 09:20:27,Subject,&lt;38.E7.30937.BD6E1BB5@ mailrelay.de&gt;,\"dmarc=fail (p=none, dis=none) header.from=domain.de\",,10.10.10.10,,,,policy,dmarc,domain.de,,False\n</code></pre>"},{"location":"splunk/","title":"Splunk","text":"<p>Starting in version 4.3.0 <code>parsedmarc</code> supports sending aggregate and/or forensic DMARC data to a Splunk HTTP Event collector (HEC).</p> <p>The project repository contains XML files for premade Splunk dashboards for aggregate and forensic DMARC reports.</p> <p>Copy and paste the contents of each file into a separate Splunk dashboard XML editor.</p> <p>Warning</p> <p>Change all occurrences of <code>index=\"email\"</code> in the XML to match your own index name.</p> <p>The Splunk dashboards display the same content and layout as the Kibana dashboards, although the Kibana dashboards have slightly easier and more flexible filtering options.</p>"},{"location":"usage/","title":"Using parsedmarc","text":""},{"location":"usage/#cli-help","title":"CLI help","text":"<pre><code>usage: parsedmarc [-h] [-c CONFIG_FILE] [--strip-attachment-payloads] [-o OUTPUT]\n                   [--aggregate-json-filename AGGREGATE_JSON_FILENAME]\n                   [--forensic-json-filename FORENSIC_JSON_FILENAME]\n                   [--aggregate-csv-filename AGGREGATE_CSV_FILENAME]\n                   [--forensic-csv-filename FORENSIC_CSV_FILENAME]\n                   [-n NAMESERVERS [NAMESERVERS ...]] [-t DNS_TIMEOUT] [--offline]\n                   [-s] [--verbose] [--debug] [--log-file LOG_FILE] [-v]\n                   [file_path ...]\n\n Parses DMARC reports\n\n positional arguments:\n   file_path             one or more paths to aggregate or forensic report\n                         files, emails, or mbox files'\n\n optional arguments:\n   -h, --help            show this help message and exit\n   -c CONFIG_FILE, --config-file CONFIG_FILE\n                         a path to a configuration file (--silent implied)\n   --strip-attachment-payloads\n                         remove attachment payloads from forensic report output\n   -o OUTPUT, --output OUTPUT\n                         write output files to the given directory\n   --aggregate-json-filename AGGREGATE_JSON_FILENAME\n                         filename for the aggregate JSON output file\n   --forensic-json-filename FORENSIC_JSON_FILENAME\n                         filename for the forensic JSON output file\n   --aggregate-csv-filename AGGREGATE_CSV_FILENAME\n                         filename for the aggregate CSV output file\n   --forensic-csv-filename FORENSIC_CSV_FILENAME\n                         filename for the forensic CSV output file\n   -n NAMESERVERS [NAMESERVERS ...], --nameservers NAMESERVERS [NAMESERVERS ...]\n                         nameservers to query\n   -t DNS_TIMEOUT, --dns_timeout DNS_TIMEOUT\n                         number of seconds to wait for an answer from DNS\n                         (default: 2.0)\n   --offline             do not make online queries for geolocation or DNS\n   -s, --silent          only print errors and warnings\n   --verbose             more verbose output\n   --debug               print debugging information\n   --log-file LOG_FILE   output logging to a file\n   -v, --version         show program's version number and exit\n</code></pre> <p>Note</p> <p>Starting in <code>parsedmarc</code> 6.0.0, most CLI options were moved to a configuration file, described below.</p>"},{"location":"usage/#configuration-file","title":"Configuration file","text":"<p><code>parsedmarc</code> can be configured by supplying the path to an INI file</p> <pre><code>parsedmarc -c /etc/parsedmarc.ini\n</code></pre> <p>For example</p> <pre><code># This is an example comment\n\n[general]\nsave_aggregate = True\nsave_forensic = True\n\n[imap]\nhost = imap.example.com\nuser = dmarcresports@example.com\npassword = $uperSecure\n\n[mailbox]\nwatch = True\ndelete = False\n\n[elasticsearch]\nhosts = 127.0.0.1:9200\nssl = False\n\n[splunk_hec]\nurl = https://splunkhec.example.com\ntoken = HECTokenGoesHere\nindex = email\n\n[s3]\nbucket = my-bucket\npath = parsedmarc\n\n[syslog]\nserver = localhost\nport = 514\n</code></pre> <p>The full set of configuration options are:</p> <ul> <li><code>general</code><ul> <li><code>save_aggregate</code> - bool: Save aggregate report data to     Elasticsearch, Splunk and/or S3</li> <li><code>save_forensic</code> - bool: Save forensic report data to     Elasticsearch, Splunk and/or S3</li> <li><code>strip_attachment_payloads</code> - bool: Remove attachment     payloads from results</li> <li><code>output</code> - str: Directory to place JSON and CSV files in.  This is required if you set either of the JSON output file options.</li> <li><code>aggregate_json_filename</code> - str: filename for the aggregate     JSON output file</li> <li><code>forensic_json_filename</code> - str: filename for the forensic     JSON output file</li> <li><code>ip_db_path</code> - str: An optional custom path to a MMDB file     from MaxMind or DBIP</li> <li><code>offline</code> - bool: Do not use online queries for geolocation     or DNS</li> <li><code>nameservers</code> - str: A comma separated list of     DNS resolvers (Default: <code>[Cloudflare's public resolvers]</code>)</li> <li><code>dns_timeout</code> - float: DNS timeout period</li> <li><code>debug</code> - bool: Print debugging messages</li> <li><code>silent</code> - bool: Only print errors (Default: <code>True</code>)</li> <li><code>log_file</code> - str: Write log messages to a file at this path</li> <li><code>n_procs</code> - int: Number of process to run in parallel when     parsing in CLI mode (Default: <code>1</code>)</li> <li> <p><code>chunk_size</code> - int: Number of files to give to each process     when running in parallel.</p> <p>Note</p> <p>Setting this to a number larger than one can improve performance when processing thousands of files</p> </li> </ul> </li> </ul> <ul> <li><code>mailbox</code><ul> <li><code>reports_folder</code> - str: The mailbox folder (or label for     Gmail) where the incoming reports can be found     (Default: <code>INBOX</code>)</li> <li><code>archive_folder</code> - str: The mailbox folder (or label for     Gmail) to sort processed emails into (Default: <code>Archive</code>)</li> <li><code>watch</code> - bool: Use the IMAP <code>IDLE</code> command to process</li> <li>messages as they arrive or poll MS Graph for new messages</li> <li><code>delete</code> - bool: Delete messages after processing them,     instead of archiving them</li> <li><code>test</code> - bool: Do not move or delete messages</li> <li><code>batch_size</code> - int: Number of messages to read and process     before saving. Default <code>10</code>. Use <code>0</code> for no limit.</li> <li><code>check_timeout</code> - int: Number of seconds to wait for a IMAP     IDLE response or the number of seconds until the next     mail check (Default: <code>30</code>)</li> </ul> </li> </ul> <ul> <li> <p><code>imap</code></p> <ul> <li><code>host</code> - str: The IMAP server hostname or IP address</li> <li> <p><code>port</code> - int: The IMAP server port (Default: <code>993</code>)</p> <p>Note</p> <p><code>%</code> characters must be escaped with another <code>%</code> character, so use <code>%%</code> wherever a <code>%</code> character is used.</p> <p>Note</p> <p>Starting in version 8.0.0, most options from the <code>imap</code> section have been moved to the <code>mailbox</code> section.</p> <p>Note</p> <p>If your host recommends another port, still try 993</p> </li> </ul> <ul> <li><code>ssl</code> - bool: Use an encrypted SSL/TLS connection     (Default: <code>True</code>)</li> <li><code>skip_certificate_verification</code> - bool: Skip certificate     verification (not recommended)</li> <li><code>user</code> - str: The IMAP user</li> <li><code>password</code> - str: The IMAP password</li> </ul> </li> </ul> <ul> <li><code>msgraph</code><ul> <li><code>auth_method</code> - str: Authentication method, valid types are     <code>UsernamePassword</code>, <code>DeviceCode</code>, or <code>ClientSecret</code>     (Default: <code>UsernamePassword</code>).</li> <li><code>user</code> - str: The M365 user, required when the auth method is     UsernamePassword</li> <li><code>password</code> - str: The user password, required when the auth     method is UsernamePassword</li> <li><code>client_id</code> - str: The app registration's client ID</li> <li><code>client_secret</code> - str: The app registration's secret</li> <li><code>tenant_id</code> - str: The Azure AD tenant ID. This is required     for all auth methods except UsernamePassword.</li> <li><code>mailbox</code> - str: The mailbox name. This defaults to the     current user if using the UsernamePassword auth method, but     could be a shared mailbox if the user has access to the mailbox</li> <li><code>token_file</code> - str: Path to save the token file     (Default: <code>.token</code>)</li> <li> <p><code>allow_unencrypted_storage</code> - bool: Allows the Azure Identity     module to fall back to unencrypted token cache (Default: <code>False</code>).     Even if enabled, the cache will always try encrypted storage first.</p> <p>Note</p> <p>You must create an app registration in Azure AD and have an admin grant the Microsoft Graph <code>Mail.ReadWrite</code> (delegated) permission to the app. If you are using <code>UsernamePassword</code> auth and the mailbox is different from the username, you must grant the app <code>Mail.ReadWrite.Shared</code>.</p> <p>Warning</p> <p>If you are using the <code>ClientSecret</code> auth method, you need to grant the <code>Mail.ReadWrite</code> (application) permission to the app. You must also restrict the application's access to a specific mailbox since it allows all mailboxes by default. Use the <code>New-ApplicationAccessPolicy</code> command in the Exchange PowerShell module. If you need to scope the policy to shared mailboxes, you can add them to a mail enabled security group and use that as the group id.</p> <pre><code>New-ApplicationAccessPolicy -AccessRight RestrictAccess\n-AppId \"&lt;CLIENT_ID&gt;\" -PolicyScopeGroupId \"&lt;MAILBOX&gt;\"\n-Description \"Restrict access to dmarc reports mailbox.\"\n</code></pre> </li> </ul> </li> </ul> <ul> <li> <p><code>elasticsearch</code></p> <ul> <li> <p><code>hosts</code> - str: A comma separated list of hostnames and ports     or URLs (e.g. <code>127.0.0.1:9200</code> or     <code>https://user:secret@localhost</code>)</p> <p>Note</p> <p>Special characters in the username or password must be URL encoded.</p> </li> </ul> <ul> <li><code>ssl</code> - bool: Use an encrypted SSL/TLS connection   (Default: <code>True</code>)</li> <li><code>cert_path</code> - str: Path to a trusted certificates</li> <li><code>index_suffix</code> - str: A suffix to apply to the index names</li> <li><code>monthly_indexes</code> - bool: Use monthly indexes instead of daily indexes</li> <li><code>number_of_shards</code> - int: The number of shards to use when   creating the index (Default: <code>1</code>)</li> <li><code>number_of_replicas</code> - int: The number of replicas to use when   creating the index (Default: <code>0</code>)</li> </ul> </li> </ul> <ul> <li><code>splunk_hec</code><ul> <li><code>url</code> - str: The URL of the Splunk HTTP Events Collector (HEC)</li> <li><code>token</code> - str: The HEC token</li> <li><code>index</code> - str: The Splunk index to use</li> <li><code>skip_certificate_verification</code> - bool: Skip certificate   verification (not recommended)</li> </ul> </li> </ul> <ul> <li><code>kafka</code><ul> <li><code>hosts</code> - str: A comma separated list of Kafka hosts</li> <li><code>user</code> - str: The Kafka user</li> <li><code>passsword</code> - str: The Kafka password</li> <li><code>ssl</code> - bool: Use an encrypted SSL/TLS connection (Default: <code>True</code>)</li> <li><code>skip_certificate_verification</code> - bool: Skip certificate   verification (not recommended)</li> <li><code>aggregate_topic</code> - str: The Kafka topic for aggregate reports</li> <li><code>forensic_topic</code> - str: The Kafka topic for forensic reports</li> </ul> </li> </ul> <ul> <li><code>smtp</code><ul> <li><code>host</code> - str: The SMTP hostname</li> <li><code>port</code> - int: The SMTP port (Default: <code>25</code>)</li> <li><code>ssl</code> - bool: Require SSL/TLS instead of using STARTTLS</li> <li><code>skip_certificate_verification</code> - bool: Skip certificate   verification (not recommended)</li> <li><code>user</code> - str: the SMTP username</li> <li><code>password</code> - str: the SMTP password</li> <li><code>from</code> - str: The From header to use in the email</li> <li><code>to</code> - list: A list of email addresses to send to</li> <li><code>subject</code> - str: The Subject header to use in the email   (Default: <code>parsedmarc report</code>)</li> <li><code>attachment</code> - str: The ZIP attachment filenames</li> <li> <p><code>message</code> - str: The email message   (Default: <code>Please see the attached parsedmarc report.</code>)</p> <p>Note</p> <p><code>%</code> characters must be escaped with another <code>%</code> character, so use <code>%%</code> wherever a <code>%</code> character is used.</p> </li> </ul> </li> </ul> <ul> <li><code>s3</code><ul> <li><code>bucket</code> - str: The S3 bucket name</li> <li><code>path</code> - str: The path to upload reports to (Default: <code>/</code>)</li> <li><code>region_name</code> - str: The region name (Optional)</li> <li><code>endpoint_url</code> - str: The endpoint URL (Optional)</li> <li><code>access_key_id</code> - str: The access key id (Optional)</li> <li><code>secret_access_key</code> - str: The secret access key (Optional)</li> </ul> </li> </ul> <ul> <li><code>syslog</code><ul> <li><code>server</code> - str: The Syslog server name or IP address</li> <li><code>port</code> - int: The UDP port to use (Default: <code>514</code>)</li> </ul> </li> </ul> <ul> <li><code>gmail_api</code><ul> <li><code>credentials_file</code> - str: Path to file containing the     credentials, None to disable (Default: <code>None</code>)</li> <li><code>token_file</code> - str: Path to save the token file     (Default: <code>.token</code>)</li> <li><code>include_spam_trash</code> - bool: Include messages in Spam and     Trash when searching reports (Default: <code>False</code>)</li> <li><code>scopes</code> - str: Comma separated list of scopes to use when     acquiring credentials     (Default: <code>https://www.googleapis.com/auth/gmail.modify</code>)</li> <li><code>oauth2_port</code> - int: The TCP port for the local server to     listen on for the OAuth2 response (Default: <code>8080</code>)</li> </ul> </li> </ul> <ul> <li><code>log_analytics</code><ul> <li><code>client_id</code> - str: The app registration's client ID</li> <li><code>client_secret</code> - str: The app registration's client secret</li> <li><code>tenant_id</code> - str: The tenant id where the app registration resides</li> <li><code>dce</code> - str: The Data Collection Endpoint (DCE). Example: <code>https://{DCE-NAME}.{REGION}.ingest.monitor.azure.com</code>.</li> <li><code>dcr_immutable_id</code> - str: The immutable ID of the Data Collection Rule (DCR)</li> <li><code>dcr_aggregate_stream</code> - str: The stream name for aggregate reports in the DCR</li> <li> <p><code>dcr_forensic_stream</code> - str: The stream name for the forensic reports in the DCR</p> <p>Note</p> <p>Information regarding the setup of the Data Collection Rule can be found here.</p> </li> </ul> </li> </ul> <p>Warning</p> <p>It is strongly recommended to not use the <code>nameservers</code> setting. By default, <code>parsedmarc</code> uses Cloudflare's public resolvers, which are much faster and more reliable than Google, Cisco OpenDNS, or even most local resolvers.</p> <p>The <code>nameservers</code> option should only be used if your network blocks DNS requests to outside resolvers.</p> <p>Note</p> <p><code>save_aggregate</code> and <code>save_forensic</code> are separate options because you may not want to save forensic reports (also known as failure reports) to your Elasticsearch instance, particularly if you are in a highly-regulated industry that handles sensitive data, such as healthcare or finance. If your legitimate outgoing email fails DMARC, it is possible that email may appear later in a forensic report.</p> <p>Forensic reports contain the original headers of an email that failed a DMARC check, and sometimes may also include the full message body, depending on the policy of the reporting organization.</p> <p>Most reporting organizations do not send forensic reports of any kind for privacy reasons. While aggregate DMARC reports are sent at least daily, it is normal to receive very few forensic reports.</p> <p>An alternative approach is to still collect forensic/failure/ruf reports in your DMARC inbox, but run <code>parsedmarc</code> with <code>save_forensic = True</code> manually on a separate IMAP folder (using the <code>reports_folder</code> option), after you have manually moved known samples you want to save to that folder (e.g. malicious samples and non-sensitive legitimate samples).</p> <p>Warning</p> <p>Elasticsearch 8 change limits policy for shards, restricting by default to 1000. parsedmarc use a shard per analyzed day. If you have more than ~3 years of data, you will need to update this limit. Check current usage (from Management -&gt; Dev Tools -&gt; Console):</p> <pre><code>GET /_cluster/health?pretty\n{\n...\n\"active_primary_shards\": 932,\n\"active_shards\": 932,\n...\n}\n</code></pre> <p>Update the limit to 2k per example:</p> <pre><code>PUT _cluster/settings\n{\n\"persistent\" : {\n    \"cluster.max_shards_per_node\" : 2000 \n}\n}\n</code></pre> <p>Increasing this value increases resource usage.</p>"},{"location":"usage/#running-parsedmarc-as-a-systemd-service","title":"Running parsedmarc as a systemd service","text":"<p>Use systemd to run <code>parsedmarc</code> as a service and process reports as they arrive.</p> <p>Protect the <code>parsedmarc</code> configuration file from prying eyes</p> <pre><code>sudo chown root:parsedmarc /etc/parsedmarc.ini\nsudo chmod u=rw,g=r,o= /etc/parsedmarc.ini\n</code></pre> <p>Create the service configuration file</p> <pre><code>sudo nano /etc/systemd/system/parsedmarc.service\n</code></pre> <pre><code>[Unit]\nDescription=parsedmarc mailbox watcher\nDocumentation=https://domainaware.github.io/parsedmarc/\nWants=network-online.target\nAfter=network.target network-online.target elasticsearch.service\n\n[Service]\nExecStart=/opt/parsedmarc/venv/bin/parsedmarc -c /etc/parsedmarc.ini\nUser=parsedmarc\nGroup=parsedmarc\nRestart=always\nRestartSec=5m\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Then, enable the service</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable parsedmarc.service\nsudo service parsedmarc restart\n</code></pre> <p>Note</p> <p>You must also run the above commands whenever you edit <code>parsedmarc.service</code>.</p> <p>Warning</p> <p>Always restart the service every time you upgrade to a new version of <code>parsedmarc</code>:</p> <pre><code>sudo service parsedmarc restart\n</code></pre> <p>To check the status of the service, run:</p> <pre><code>service parsedmarc status\n</code></pre> <p>Note</p> <p>In the event of a crash, systemd will restart the service after 10 minutes, but the <code>service parsedmarc status</code> command will only show the logs for the current process. To view the logs for previous runs as well as the current process (newest to oldest), run:</p> <pre><code>journalctl -u parsedmarc.service -r\n</code></pre>"},{"location":"reference/parsedmarc/","title":"Index","text":""},{"location":"reference/parsedmarc/#parsedmarc","title":"parsedmarc","text":"<p>A Python package for parsing DMARC reports</p>"},{"location":"reference/parsedmarc/#parsedmarc.email_results","title":"email_results","text":"<pre><code>email_results(\n    results: SortedReportContainer,\n    host: str,\n    mail_from: str,\n    mail_to: list[str],\n    mail_cc: list[str] | None = None,\n    mail_bcc: list[str] | None = None,\n    port: int = 0,\n    require_encryption: bool = False,\n    verify: bool = True,\n    username: str | None = None,\n    password: str | None = None,\n    subject: str | None = None,\n    attachment_filename: str | None = None,\n    message: str | None = None,\n) -&gt; None\n</code></pre> <p>Emails parsing results as a zip file</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>SortedReportContainer</code> <p>Parsing results</p> required <code>host</code> <code>str</code> <p>Mail server hostname or IP address</p> required <code>mail_from</code> <code>str</code> <p>The value of the message from header</p> required <code>mail_to</code> <code>list[str]</code> <p>A list of addresses to mail to</p> required <code>mail_cc</code> <code>list[str] | None</code> <p>A list of addresses to CC</p> <code>None</code> <code>mail_bcc</code> <code>list[str] | None</code> <p>A list addresses to BCC</p> <code>None</code> <code>port</code> <code>int</code> <p>Port to use</p> <code>0</code> <code>require_encryption</code> <code>bool</code> <p>Require a secure connection from the start</p> <code>False</code> <code>verify</code> <code>bool</code> <p>verify the SSL/TLS certificate</p> <code>True</code> <code>username</code> <code>str | None</code> <p>An optional username</p> <code>None</code> <code>password</code> <code>str | None</code> <p>An optional password</p> <code>None</code> <code>subject</code> <code>str | None</code> <p>Overrides the default message subject</p> <code>None</code> <code>attachment_filename</code> <code>str | None</code> <p>Override the default attachment filename</p> <code>None</code> <code>message</code> <code>str | None</code> <p>Override the default plain text body</p> <code>None</code>"},{"location":"reference/parsedmarc/#parsedmarc.get_dmarc_reports_from_mailbox","title":"get_dmarc_reports_from_mailbox","text":"<pre><code>get_dmarc_reports_from_mailbox(\n    connection: MailboxConnection,\n    reports_folder: str = \"INBOX\",\n    archive_folder: str = \"Archive\",\n    delete: bool = False,\n    test: bool = False,\n    ip_db_path: str | None = None,\n    offline: bool = False,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 6.0,\n    strip_attachment_payloads: bool = False,\n    results: SortedReportContainer | None = None,\n    batch_size: int = 10,\n    create_folders: bool = True,\n) -&gt; SortedReportContainer\n</code></pre> <p>Fetches and parses DMARC reports from a mailbox</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>MailboxConnection</code> <p>A Mailbox connection object</p> required <code>reports_folder</code> <code>str</code> <p>The folder where reports can be found</p> <code>'INBOX'</code> <code>archive_folder</code> <code>str</code> <p>The folder to move processed mail to</p> <code>'Archive'</code> <code>delete</code> <code>bool</code> <p>Delete  messages after processing them</p> <code>False</code> <code>test</code> <code>bool</code> <p>Do not move or delete messages after processing them</p> <code>False</code> <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>offline</code> <code>bool</code> <p>Do not query online for geolocation or DNS</p> <code>False</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of DNS nameservers to query</p> <code>None</code> <code>dns_timeout</code> <code>float</code> <p>Set the DNS query timeout</p> <code>6.0</code> <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <code>results</code> <code>SortedReportContainer | None</code> <p>Results from the previous run</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Number of messages to read and process before saving (use 0 for no limit)</p> <code>10</code> <code>create_folders</code> <code>bool</code> <p>Whether to create the destination folders (not used in watch)</p> <code>True</code> <p>Returns:</p> Type Description <code>SortedReportContainer</code> <p>collected reported</p>"},{"location":"reference/parsedmarc/#parsedmarc.get_dmarc_reports_from_mbox","title":"get_dmarc_reports_from_mbox","text":"<pre><code>get_dmarc_reports_from_mbox(\n    source: str,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 2.0,\n    strip_attachment_payloads: bool = False,\n    ip_db_path: str | None = None,\n    offline: bool = False,\n) -&gt; SortedReportContainer\n</code></pre> <p>Parses a mailbox in mbox format containing e-mails with attached DMARC reports</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>A path to a mbox file</p> required <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>dns_timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>offline</code> <code>bool</code> <p>Do not make online queries for geolocation or DNS</p> <code>False</code> <p>Returns:</p> Type Description <code>SortedReportContainer</code> <p>container of reports</p>"},{"location":"reference/parsedmarc/#parsedmarc.get_report_zip","title":"get_report_zip","text":"<pre><code>get_report_zip(results: SortedReportContainer) -&gt; bytes\n</code></pre> <p>Creates a zip file of parsed report output</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>SortedReportContainer</code> <p>The parsed results</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>raw zip file</p>"},{"location":"reference/parsedmarc/#parsedmarc.parse_aggregate_report_file","title":"parse_aggregate_report_file","text":"<pre><code>parse_aggregate_report_file(\n    source: bytes | str | BinaryIO,\n    offline: bool = False,\n    ip_db_path: str | None = None,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 2.0,\n    keep_alive: Callable | None = None,\n) -&gt; AggregateReport\n</code></pre> <p>Parse a file at the given path, a file-like object. or bytes as an aggregate DMARC report</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>bytes | str | BinaryIO</code> <p>A path to a file, a file like object, or bytes</p> required <code>offline</code> <code>bool</code> <p>Do not query online for geolocation or DNS</p> <code>False</code> <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>dns_timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <code>keep_alive</code> <code>Callable | None</code> <p>Keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>AggregateReport</code> <p>The parsed DMARC aggregate report</p>"},{"location":"reference/parsedmarc/#parsedmarc.parse_aggregate_report_xml","title":"parse_aggregate_report_xml","text":"<pre><code>parse_aggregate_report_xml(\n    xml: str,\n    ip_db_path: str | None = None,\n    offline: bool = False,\n    nameservers: list[str] | None = None,\n    timeout: float = 2.0,\n    keep_alive: Callable | None = None,\n) -&gt; AggregateReport\n</code></pre> <p>Parses a DMARC XML report string and returns an AggregateReport</p> <p>Parameters:</p> Name Type Description Default <code>xml</code> <code>str</code> <p>A string of DMARC aggregate report XML</p> required <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>offline</code> <code>bool</code> <p>Do not query online for geolocation or DNS</p> <code>False</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <code>keep_alive</code> <code>Callable | None</code> <p>Keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>AggregateReport</code> <p>The parsed aggregate DMARC report</p>"},{"location":"reference/parsedmarc/#parsedmarc.parse_forensic_report","title":"parse_forensic_report","text":"<pre><code>parse_forensic_report(\n    feedback_report: str,\n    sample: str,\n    msg_date: datetime,\n    offline: bool = False,\n    ip_db_path: str | None = None,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 2.0,\n    strip_attachment_payloads: bool = False,\n) -&gt; ForensicReport\n</code></pre> <p>Converts a DMARC forensic report and sample to a ForensicReport</p> <p>Parameters:</p> Name Type Description Default <code>feedback_report</code> <code>str</code> <p>A message's feedback report as a string</p> required <code>sample</code> <code>str</code> <p>The RFC 822 headers or RFC 822 message sample</p> required <code>msg_date</code> <code>datetime</code> <p>The message's date header</p> required <code>offline</code> <code>bool</code> <p>Do not query online for geolocation or DNS</p> <code>False</code> <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>nameservers</code> <code>list</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>dns_timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <p>Returns:</p> Type Description <code>ForensicReport</code> <p>A parsed report and sample</p>"},{"location":"reference/parsedmarc/#parsedmarc.parse_report_email","title":"parse_report_email","text":"<pre><code>parse_report_email(\n    source: bytes | str,\n    offline: bool = False,\n    ip_db_path: str | None = None,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 2.0,\n    strip_attachment_payloads: bool = False,\n    keep_alive: Callable | None = None,\n) -&gt; Report\n</code></pre> <p>Parse a DMARC report from an email</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>bytes | str</code> <p>An emailed DMARC report in RFC 822 format, as bytes or a string</p> required <code>offline</code> <code>bool</code> <p>Do not query online for geolocation on DNS</p> <code>False</code> <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use</p> <code>None</code> <code>dns_timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <code>keep_alive</code> <code>Callable | None</code> <p>keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>Report</code> <p>report container</p>"},{"location":"reference/parsedmarc/#parsedmarc.parse_report_file","title":"parse_report_file","text":"<pre><code>parse_report_file(\n    source: str | bytes | BinaryIO,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 2.0,\n    strip_attachment_payloads: bool = False,\n    ip_db_path: str | None = None,\n    offline: bool = False,\n    keep_alive: Callable | None = None,\n) -&gt; Report\n</code></pre> <p>Parse a DMARC aggregate or forensic file at the given path, a file-like object. or bytes</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | bytes | BinaryIO</code> <p>A path to a file, a file like object, or bytes</p> required <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>dns_timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>offline</code> <code>bool</code> <p>Do not make online queries for geolocation or DNS</p> <code>False</code> <code>keep_alive</code> <code>Callable | None</code> <p>Keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>Report</code> <p>The parsed DMARC report</p>"},{"location":"reference/parsedmarc/#parsedmarc.parsed_aggregate_reports_to_csv","title":"parsed_aggregate_reports_to_csv","text":"<pre><code>parsed_aggregate_reports_to_csv(\n    reports: AggregateReport | list[AggregateReport],\n) -&gt; str\n</code></pre> <p>Convert one or more parsed aggregate reports to flat CSV format, including headers</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>AggregateReport | list[AggregateReport]</code> <p>A parsed aggregate report or list of parsed aggregate reports</p> required <p>Returns:</p> Type Description <code>str</code> <p>Parsed aggregate report data in flat CSV format, including headers</p>"},{"location":"reference/parsedmarc/#parsedmarc.parsed_aggregate_reports_to_csv_rows","title":"parsed_aggregate_reports_to_csv_rows","text":"<pre><code>parsed_aggregate_reports_to_csv_rows(\n    reports: AggregateReport | list[AggregateReport],\n) -&gt; list[dict[str, str | int | bool]]\n</code></pre> <p>Convert one or more parsed aggregate reports to list of dicts in flat CSV format</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>AggregateReport | list[AggregateReport]</code> <p>A parsed aggregate report or list of parsed aggregate reports</p> required <p>Returns:</p> Type Description <code>list[dict[str, str | int | bool]]</code> <p>Parsed aggregate report data as a list of dicts in flat CSV format</p>"},{"location":"reference/parsedmarc/#parsedmarc.parsed_forensic_reports_to_csv","title":"parsed_forensic_reports_to_csv","text":"<pre><code>parsed_forensic_reports_to_csv(\n    reports: ForensicReport | list[ForensicReport],\n) -&gt; str\n</code></pre> <p>Convert one or more parsed forensic reports to flat CSV format, including headers</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>ForensicReport | list[ForensicReport]</code> <p>A parsed forensic report or list of parsed forensic reports</p> required <p>Returns:</p> Type Description <code>str</code> <p>Parsed forensic report data in flat CSV format, including headers</p>"},{"location":"reference/parsedmarc/#parsedmarc.parsed_forensic_reports_to_csv_rows","title":"parsed_forensic_reports_to_csv_rows","text":"<pre><code>parsed_forensic_reports_to_csv_rows(\n    reports: ForensicReport | list[ForensicReport],\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Convert one or more parsed forensic reports to a list of dicts in flat CSV format</p> <p>Parameters:</p> Name Type Description Default <code>reports</code> <code>ForensicReport | list[ForensicReport]</code> <p>A parsed forensic report or list of parsed forensic reports</p> required <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>Parsed forensic report data as a list of dicts in flat CSV format</p>"},{"location":"reference/parsedmarc/#parsedmarc.save_output","title":"save_output","text":"<pre><code>save_output(\n    results: SortedReportContainer,\n    output_directory: str = \"output\",\n    aggregate_json_filename: str = \"aggregate.json\",\n    forensic_json_filename: str = \"forensic.json\",\n    aggregate_csv_filename: str = \"aggregate.csv\",\n    forensic_csv_filename: str = \"forensic.csv\",\n) -&gt; None\n</code></pre> <p>Save report data in the given directory</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>SortedReportContainer</code> <p>Parsing results</p> required <code>output_directory</code> <code>str</code> <p>The path to the directory to save in</p> <code>'output'</code> <code>aggregate_json_filename</code> <code>str</code> <p>Filename for the aggregate JSON file</p> <code>'aggregate.json'</code> <code>forensic_json_filename</code> <code>str</code> <p>Filename for the forensic JSON file</p> <code>'forensic.json'</code> <code>aggregate_csv_filename</code> <code>str</code> <p>Filename for the aggregate CSV file</p> <code>'aggregate.csv'</code> <code>forensic_csv_filename</code> <code>str</code> <p>Filename for the forensic CSV file</p> <code>'forensic.csv'</code>"},{"location":"reference/parsedmarc/#parsedmarc.watch_inbox","title":"watch_inbox","text":"<pre><code>watch_inbox(\n    mailbox_connection: MailboxConnection,\n    callback: Callable,\n    reports_folder: str = \"INBOX\",\n    archive_folder: str = \"Archive\",\n    delete: bool = False,\n    test: bool = False,\n    check_timeout: int = 30,\n    ip_db_path: str | None = None,\n    offline: bool = False,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 6.0,\n    strip_attachment_payloads: bool = False,\n    batch_size: int | None = None,\n) -&gt; None\n</code></pre> <p>Watches a mailbox for new messages and sends the results to a callback function</p> <p>Parameters:</p> Name Type Description Default <code>mailbox_connection</code> <code>MailboxConnection</code> <p>The mailbox connection object</p> required <code>callback</code> <code>Callable</code> <p>The callback function to receive the parsing results</p> required <code>reports_folder</code> <code>str</code> <p>The IMAP folder where reports can be found</p> <code>'INBOX'</code> <code>archive_folder</code> <code>str</code> <p>The folder to move processed mail to</p> <code>'Archive'</code> <code>delete</code> <code>bool</code> <p>Delete  messages after processing them</p> <code>False</code> <code>test</code> <code>bool</code> <p>Do not move or delete messages after processing them</p> <code>False</code> <code>check_timeout</code> <code>int</code> <p>Number of seconds to wait for a IMAP IDLE response or the next mail check</p> <code>30</code> <code>ip_db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>offline</code> <code>bool</code> <p>Do not query online for geolocation or DNS</p> <code>False</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>dns_timeout</code> <code>float</code> <p>Set the DNS query timeout</p> <code>6.0</code> <code>strip_attachment_payloads</code> <code>bool</code> <p>Replace attachment payloads in forensic report samples with None</p> <code>False</code> <code>batch_size</code> <code>int | None</code> <p>Number of messages to read and process before saving</p> <code>None</code>"},{"location":"reference/parsedmarc/cli/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> cli","text":""},{"location":"reference/parsedmarc/cli/#parsedmarc.cli","title":"parsedmarc.cli","text":"<p>A CLI for parsing DMARC reports</p>"},{"location":"reference/parsedmarc/cli/#parsedmarc.cli.cli_parse","title":"cli_parse","text":"<pre><code>cli_parse(\n    file_path,\n    sa,\n    nameservers,\n    dns_timeout,\n    ip_db_path,\n    offline,\n)\n</code></pre> <p>Separated this function for multiprocessing</p>"},{"location":"reference/parsedmarc/elastic/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> elastic","text":""},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic","title":"parsedmarc.elastic","text":""},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic.AlreadySaved","title":"AlreadySaved","text":"<p>             Bases: <code>ValueError</code></p> <p>Raised when a report to be saved matches an existing report</p>"},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic.ElasticsearchError","title":"ElasticsearchError","text":"<pre><code>ElasticsearchError(message: str | Exception)\n</code></pre> <p>             Bases: <code>Exception</code></p> <p>Raised when an Elasticsearch error occurs</p>"},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic.create_indexes","title":"create_indexes","text":"<pre><code>create_indexes(\n    names: list[str], settings: dict[str, int] | None = None\n) -&gt; None\n</code></pre> <p>Create Elasticsearch indexes</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>list[str]</code> <p>A list of index names</p> required <code>settings</code> <code>dict[str, int] | None</code> <p>Index settings</p> <code>None</code>"},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic.migrate_indexes","title":"migrate_indexes","text":"<pre><code>migrate_indexes(\n    aggregate_indexes: list[str] | None = None,\n    forensic_indexes: list[str] | None = None,\n)\n</code></pre> <p>Update index mappings</p> <p>Parameters:</p> Name Type Description Default <code>aggregate_indexes</code> <code>list[str] | None</code> <p>A list of aggregate index names</p> <code>None</code> <code>forensic_indexes</code> <code>list[str] | None</code> <p>A list of forensic index names</p> <code>None</code>"},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic.save_aggregate_report_to_elasticsearch","title":"save_aggregate_report_to_elasticsearch","text":"<pre><code>save_aggregate_report_to_elasticsearch(\n    report: AggregateReport,\n    index_suffix: str | None = None,\n    monthly_indexes: bool = False,\n    number_of_shards: int = 1,\n    number_of_replicas: int = 0,\n) -&gt; None\n</code></pre> <p>Saves a parsed DMARC aggregate report to ElasticSearch</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>AggregateReport</code> <p>A parsed forensic report</p> required <code>index_suffix</code> <code>str | None</code> <p>The suffix of the name of the index to save to</p> <code>None</code> <code>monthly_indexes</code> <code>bool</code> <p>Use monthly indexes instead of daily indexes</p> <code>False</code> <code>number_of_shards</code> <code>int</code> <p>The number of shards to use in the index</p> <code>1</code> <code>number_of_replicas</code> <code>int</code> <p>The number of replicas to use in the index</p> <code>0</code>"},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic.save_forensic_report_to_elasticsearch","title":"save_forensic_report_to_elasticsearch","text":"<pre><code>save_forensic_report_to_elasticsearch(\n    report: ForensicReport,\n    index_suffix: str | None = None,\n    monthly_indexes: bool = False,\n    number_of_shards: int = 1,\n    number_of_replicas: int = 0,\n) -&gt; None\n</code></pre> <p>Save a parsed DMARC forensic report to ElasticSearch</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>ForensicReport</code> <p>A parsed forensic report</p> required <code>index_suffix</code> <code>str | None</code> <p>The suffix of the name of the index to save to</p> <code>None</code> <code>monthly_indexes</code> <code>bool</code> <p>Use monthly indexes instead of daily indexes</p> <code>False</code> <code>number_of_shards</code> <code>int</code> <p>The number of shards to use in the index</p> <code>1</code> <code>number_of_replicas</code> <code>int</code> <p>The number of replicas to use in the index</p> <code>0</code>"},{"location":"reference/parsedmarc/elastic/#parsedmarc.elastic.set_hosts","title":"set_hosts","text":"<pre><code>set_hosts(\n    hosts: str | list[str],\n    use_ssl: bool = False,\n    ssl_cert_path: str | None = None,\n    username: str | None = None,\n    password: str | None = None,\n    apiKey: str | None = None,\n    timeout: float = 60.0,\n) -&gt; None\n</code></pre> <p>Set the Elasticsearch host(s) to use</p> <p>Parameters:</p> Name Type Description Default <code>hosts</code> <code>str | list[str]</code> <p>A single hostname or URL, or list of hostnames or URLs</p> required <code>use_ssl</code> <code>bool</code> <p>Use a HTTPS connection to the server</p> <code>False</code> <code>ssl_cert_path</code> <code>str | None</code> <p>Path to the certificate chain</p> <code>None</code> <code>username</code> <code>str | None</code> <p>The username to use for authentication</p> <code>None</code> <code>password</code> <code>str | None</code> <p>The password to use for authentication</p> <code>None</code> <code>apiKey</code> <code>str | None</code> <p>The Base64 encoded API key to use for authentication</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Timeout in seconds</p> <code>60.0</code>"},{"location":"reference/parsedmarc/kafkaclient/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> kafkaclient","text":""},{"location":"reference/parsedmarc/kafkaclient/#parsedmarc.kafkaclient","title":"parsedmarc.kafkaclient","text":""},{"location":"reference/parsedmarc/kafkaclient/#parsedmarc.kafkaclient.KafkaClient","title":"KafkaClient","text":"<pre><code>KafkaClient(\n    kafka_hosts: list[str],\n    ssl: bool = False,\n    username: str | None = None,\n    password: str | None = None,\n    ssl_context: SSLContext | None = None,\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>kafka_hosts</code> <code>list[str]</code> <p>A list of Kafka hostnames (with optional port numbers)</p> required <code>ssl</code> <code>bool</code> <p>Use a SSL/TLS connection. This is implied <code>True</code> if <code>username</code> or <code>password</code> is supplied.</p> <code>False</code> <code>username</code> <code>str | None</code> <p>An optional username</p> <code>None</code> <code>password</code> <code>str | None</code> <p>An optional password</p> <code>None</code> <code>ssl_context</code> <code>SSLContext | None</code> <p>SSL context options</p> <code>None</code> Note <p>When using Azure Event Hubs, the <code>username</code> is literally <code>$ConnectionString</code>, and the <code>password</code> is the Azure Event Hub connection string.</p>"},{"location":"reference/parsedmarc/kafkaclient/#parsedmarc.kafkaclient.KafkaClient.generate_daterange","title":"generate_daterange  <code>staticmethod</code>","text":"<pre><code>generate_daterange(report)\n</code></pre> <p>Creates a date_range timestamp with format YYYY-MM-DD-T-HH:MM:SS based on begin and end dates for easier parsing in Kibana.</p> <p>Move to utils to avoid duplication w/ elastic?</p>"},{"location":"reference/parsedmarc/kafkaclient/#parsedmarc.kafkaclient.KafkaClient.save_aggregate_reports_to_kafka","title":"save_aggregate_reports_to_kafka","text":"<pre><code>save_aggregate_reports_to_kafka(\n    aggregate_reports: AggregateReport\n    | list[AggregateReport],\n    aggregate_topic: str,\n) -&gt; None\n</code></pre> <p>Saves aggregate DMARC reports to Kafka</p> <p>Parameters:</p> Name Type Description Default <code>aggregate_reports</code> <code>AggregateReport | list[AggregateReport]</code> <p>Aggregate reports to save to Kafka</p> required <code>aggregate_topic</code> <code>str</code> <p>The name of the Kafka topic</p> required"},{"location":"reference/parsedmarc/kafkaclient/#parsedmarc.kafkaclient.KafkaClient.save_forensic_reports_to_kafka","title":"save_forensic_reports_to_kafka","text":"<pre><code>save_forensic_reports_to_kafka(\n    forensic_reports: ForensicReport | list[ForensicReport],\n    forensic_topic: str,\n) -&gt; None\n</code></pre> <p>Saves forensic DMARC reports to Kafka, sends individual records (slices) since Kafka requires messages to be &lt;= 1MB by default.</p> <p>Parameters:</p> Name Type Description Default <code>forensic_reports</code> <code>ForensicReport | list[ForensicReport]</code> <p>Forensic reports to save to Kafka</p> required <code>forensic_topic</code> <code>str</code> <p>The name of the Kafka topic</p> required"},{"location":"reference/parsedmarc/kafkaclient/#parsedmarc.kafkaclient.KafkaClient.strip_metadata","title":"strip_metadata  <code>staticmethod</code>","text":"<pre><code>strip_metadata(report)\n</code></pre> <p>Duplicates org_name, org_email and report_id into JSON root and removes report_metadata key to bring it more inline with Elastic output.</p>"},{"location":"reference/parsedmarc/kafkaclient/#parsedmarc.kafkaclient.KafkaError","title":"KafkaError","text":"<pre><code>KafkaError(message: str | Exception)\n</code></pre> <p>             Bases: <code>RuntimeError</code></p> <p>Raised when a Kafka error occurs</p>"},{"location":"reference/parsedmarc/log/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> log","text":""},{"location":"reference/parsedmarc/log/#parsedmarc.log","title":"parsedmarc.log","text":""},{"location":"reference/parsedmarc/loganalytics/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> loganalytics","text":""},{"location":"reference/parsedmarc/loganalytics/#parsedmarc.loganalytics","title":"parsedmarc.loganalytics","text":""},{"location":"reference/parsedmarc/loganalytics/#parsedmarc.loganalytics.LogAnalyticsClient","title":"LogAnalyticsClient","text":"<pre><code>LogAnalyticsClient(\n    client_id: str,\n    client_secret: str,\n    tenant_id: str,\n    dce: str,\n    dcr_immutable_id: str,\n    dcr_aggregate_stream: str | None = None,\n    dcr_forensic_stream: str | None = None,\n)\n</code></pre> <p>Azure Log Analytics Client</p> <p>Pushes the  DMARC reports to Log Analytics via Data Collection Rules.</p> References <ul> <li>https://learn.microsoft.com/en-us/azure/azure-monitor/logs/logs-ingestion-api-overview</li> </ul> <p>Parameters:</p> Name Type Description Default <code>client_id</code> <code>str</code> <p>The client ID of the service principle.</p> required <code>client_secret</code> <code>str</code> <p>The client secret of the service principle.</p> required <code>tenant_id</code> <code>str</code> <p>The tenant ID where the service principle resides.</p> required <code>dce</code> <code>str</code> <p>The Data Collection Endpoint (DCE) used by the Data Collection Rule (DCR).</p> required <code>dcr_immutable_id</code> <code>str</code> <p>The immutable ID of the Data Collection Rule (DCR).</p> required <code>dcr_aggregate_stream</code> <code>str | None</code> <p>The Stream name where the Aggregate DMARC reports need to be pushed.</p> <code>None</code> <code>dcr_forensic_stream</code> <code>str | None</code> <p>The Stream name where the Forensic DMARC reports need to be pushed.</p> <code>None</code>"},{"location":"reference/parsedmarc/loganalytics/#parsedmarc.loganalytics.LogAnalyticsClient.publish_results","title":"publish_results","text":"<pre><code>publish_results(\n    results: SortedReportContainer,\n    save_aggregate: bool,\n    save_forensic: bool,\n) -&gt; None\n</code></pre> <p>Publish DMARC reports to Log Analytics via Data Collection Rules (DCR).</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>SortedReportContainer</code> <p>The DMARC reports (Aggregate &amp; Forensic)</p> required <code>save_aggregate</code> <code>bool</code> <p>Whether Aggregate reports can be saved into Log Analytics</p> required <code>save_forensic</code> <code>bool</code> <p>Whether Forensic reports can be saved into Log Analytics</p> required"},{"location":"reference/parsedmarc/loganalytics/#parsedmarc.loganalytics.LogAnalyticsException","title":"LogAnalyticsException","text":"<p>             Bases: <code>Exception</code></p> <p>Errors originating from LogsIngestionClient</p>"},{"location":"reference/parsedmarc/parser/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> parser","text":""},{"location":"reference/parsedmarc/parser/#parsedmarc.parser","title":"parsedmarc.parser","text":""},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.InvalidAggregateReport","title":"InvalidAggregateReport","text":"<p>             Bases: <code>InvalidDMARCReport</code></p> <p>Raised when an invalid DMARC aggregate report is encountered</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.InvalidDMARCReport","title":"InvalidDMARCReport","text":"<p>             Bases: <code>ParserError</code></p> <p>Raised when an invalid DMARC report is encountered</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.InvalidForensicReport","title":"InvalidForensicReport","text":"<p>             Bases: <code>InvalidDMARCReport</code></p> <p>Raised when an invalid DMARC forensic report is encountered</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.ParserError","title":"ParserError","text":"<p>             Bases: <code>RuntimeError</code></p> <p>Raised whenever the parser fails for some reason</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.ReportParser","title":"ReportParser","text":"<pre><code>ReportParser(\n    offline: bool = False,\n    ip_db_path: str | None = None,\n    nameservers: list[str] | None = None,\n    dns_timeout: float = 2.0,\n)\n</code></pre> <p>Report Parser</p> <p>Parses reports from messages and files.</p> <p>Can handled the following types of reports:</p> <ul> <li>DMARC<ul> <li>Aggregate</li> <li>Forensic</li> </ul> </li> </ul>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.ReportParser.parse_aggregate_report_file","title":"parse_aggregate_report_file","text":"<pre><code>parse_aggregate_report_file(\n    source: bytes | str | BinaryIO,\n    keep_alive: Callable | None = None,\n) -&gt; AggregateReport\n</code></pre> <p>Parse a file at the given path, a file-like object. or bytes as an aggregate DMARC report</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>bytes | str | BinaryIO</code> <p>A path to a file, a file like object, or bytes</p> required <code>keep_alive</code> <code>Callable | None</code> <p>Keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>AggregateReport</code> <p>The parsed DMARC aggregate report</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.ReportParser.parse_aggregate_report_xml","title":"parse_aggregate_report_xml","text":"<pre><code>parse_aggregate_report_xml(\n    xml: str, keep_alive: Callable | None = None\n) -&gt; AggregateReport\n</code></pre> <p>Parses a DMARC XML report string and returns an AggregateReport</p> <p>Parameters:</p> Name Type Description Default <code>xml</code> <code>str</code> <p>A string of DMARC aggregate report XML</p> required <code>keep_alive</code> <code>Callable | None</code> <p>Keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>AggregateReport</code> <p>The parsed aggregate DMARC report</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.ReportParser.parse_forensic_report","title":"parse_forensic_report","text":"<pre><code>parse_forensic_report(\n    feedback_report: str,\n    sample: str,\n    msg_date: datetime,\n    strip_attachment_payloads: bool = False,\n) -&gt; ForensicReport\n</code></pre> <p>Converts a DMARC forensic report and sample to a ForensicReport</p> <p>Parameters:</p> Name Type Description Default <code>feedback_report</code> <code>str</code> <p>A message's feedback report as a string</p> required <code>sample</code> <code>str</code> <p>The RFC 822 headers or RFC 822 message sample</p> required <code>msg_date</code> <code>datetime</code> <p>The message's date header</p> required <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <p>Returns:</p> Type Description <code>ForensicReport</code> <p>A parsed report and sample</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.ReportParser.parse_report_email","title":"parse_report_email","text":"<pre><code>parse_report_email(\n    source: bytes | str,\n    strip_attachment_payloads: bool = False,\n    keep_alive: Callable | None = None,\n) -&gt; Report\n</code></pre> <p>Parse a DMARC report from an email</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>bytes | str</code> <p>An emailed DMARC report in RFC 822 format, as bytes or a string</p> required <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <code>keep_alive</code> <code>Callable | None</code> <p>keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>Report</code> <p>the report parsed from the email</p>"},{"location":"reference/parsedmarc/parser/#parsedmarc.parser.ReportParser.parse_report_file","title":"parse_report_file","text":"<pre><code>parse_report_file(\n    source: str | bytes | BinaryIO,\n    strip_attachment_payloads: bool = False,\n    keep_alive: Callable | None = None,\n) -&gt; Report\n</code></pre> <p>Parse a DMARC aggregate or forensic file at the given path, a file-like object. or bytes</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | bytes | BinaryIO</code> <p>A path to a file, a file like object, or bytes</p> required <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads from forensic report results</p> <code>False</code> <code>keep_alive</code> <code>Callable | None</code> <p>Keep alive function</p> <code>None</code> <p>Returns:</p> Type Description <code>Report</code> <p>The parsed DMARC report</p>"},{"location":"reference/parsedmarc/reports/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> reports","text":""},{"location":"reference/parsedmarc/reports/#parsedmarc.reports","title":"parsedmarc.reports","text":""},{"location":"reference/parsedmarc/reports/#parsedmarc.reports.AggregateReport","title":"AggregateReport","text":"<pre><code>AggregateReport(data: dict[str, Any])\n</code></pre> <p>             Bases: <code>Report</code></p> <p>A DMARC Aggregate Report</p>"},{"location":"reference/parsedmarc/reports/#parsedmarc.reports.AggregateReport.to_csv_rows","title":"to_csv_rows","text":"<pre><code>to_csv_rows() -&gt; list[dict[str, Any]]\n</code></pre> <p>Convert this Aggregate report into a CSV compatible row</p> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>rows as a dicts</p>"},{"location":"reference/parsedmarc/reports/#parsedmarc.reports.ForensicReport","title":"ForensicReport","text":"<pre><code>ForensicReport(data: dict[str, Any])\n</code></pre> <p>             Bases: <code>Report</code></p> <p>A DMARC Forensic Report</p>"},{"location":"reference/parsedmarc/reports/#parsedmarc.reports.ForensicReport.to_csv_row","title":"to_csv_row","text":"<pre><code>to_csv_row() -&gt; dict[str, Any]\n</code></pre> <p>Convert this Forensic report into a CSV compatible row</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>row as a dict</p>"},{"location":"reference/parsedmarc/reports/#parsedmarc.reports.Report","title":"Report","text":"<pre><code>Report(data: dict[str, Any])\n</code></pre> <p>Base class for all reports</p>"},{"location":"reference/parsedmarc/reports/#parsedmarc.reports.SortedReportContainer","title":"SortedReportContainer","text":"<pre><code>SortedReportContainer(\n    existing_aggregate_reports: list[AggregateReport]\n    | None = None,\n    existing_forensic_reports: list[ForensicReport]\n    | None = None,\n)\n</code></pre>"},{"location":"reference/parsedmarc/reports/#parsedmarc.reports.SortedReportContainer.add_report","title":"add_report","text":"<pre><code>add_report(report: Report) -&gt; str\n</code></pre> <p>Add a report to this container returning the added type.</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>Report</code> <p>the report to add</p> required <p>Returns:</p> Type Description <code>str</code> <p>the type of report added</p>"},{"location":"reference/parsedmarc/s3/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> s3","text":""},{"location":"reference/parsedmarc/s3/#parsedmarc.s3","title":"parsedmarc.s3","text":""},{"location":"reference/parsedmarc/s3/#parsedmarc.s3.S3Client","title":"S3Client","text":"<pre><code>S3Client(\n    bucket_name: str,\n    bucket_path: str,\n    region_name: str | None = None,\n    endpoint_url: str | None = None,\n    access_key_id: str | None = None,\n    secret_access_key: str | None = None,\n)\n</code></pre> <p>A client for a Amazon S3</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The S3 Bucket</p> required <code>bucket_path</code> <code>str</code> <p>The path to save reports</p> required <code>region_name</code> <code>str | None</code> <p>The region name</p> <code>None</code> <code>endpoint_url</code> <code>str | None</code> <p>The endpoint URL</p> <code>None</code> <code>access_key_id</code> <code>str | None</code> <p>The access key id</p> <code>None</code> <code>secret_access_key</code> <code>str | None</code> <p>The secret access key</p> <code>None</code>"},{"location":"reference/parsedmarc/splunk/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> splunk","text":""},{"location":"reference/parsedmarc/splunk/#parsedmarc.splunk","title":"parsedmarc.splunk","text":""},{"location":"reference/parsedmarc/splunk/#parsedmarc.splunk.HECClient","title":"HECClient","text":"<pre><code>HECClient(\n    url: str,\n    access_token: str,\n    index: str,\n    source: str = \"parsedmarc\",\n    verify: bool = True,\n    timeout: int = 60,\n)\n</code></pre> <p>A client for a Splunk HTTP Events Collector (HEC)</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the HEC</p> required <code>access_token</code> <code>str</code> <p>The HEC access token</p> required <code>index</code> <code>str</code> <p>The name of the index</p> required <code>source</code> <code>str</code> <p>The source name</p> <code>'parsedmarc'</code> <code>verify</code> <code>bool</code> <p>Verify SSL certificates</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Number of seconds to wait for the server to send data before giving up</p> <code>60</code>"},{"location":"reference/parsedmarc/splunk/#parsedmarc.splunk.HECClient.save_aggregate_reports_to_splunk","title":"save_aggregate_reports_to_splunk","text":"<pre><code>save_aggregate_reports_to_splunk(\n    aggregate_reports: AggregateReport\n    | list[AggregateReport],\n)\n</code></pre> <p>Save aggregate DMARC reports to Splunk</p> <p>Parameters:</p> Name Type Description Default <code>aggregate_reports</code> <code>AggregateReport | list[AggregateReport]</code> <p>Aggregate reports to save in Splunk</p> required"},{"location":"reference/parsedmarc/splunk/#parsedmarc.splunk.HECClient.save_forensic_reports_to_splunk","title":"save_forensic_reports_to_splunk","text":"<pre><code>save_forensic_reports_to_splunk(\n    forensic_reports: ForensicReport | list[ForensicReport],\n)\n</code></pre> <p>Save forensic DMARC reports to Splunk</p> <p>Parameters:</p> Name Type Description Default <code>forensic_reports</code> <code>ForensicReport | list[ForensicReport]</code> <p>Forensic reports to save in Splunk</p> required"},{"location":"reference/parsedmarc/splunk/#parsedmarc.splunk.SplunkError","title":"SplunkError","text":"<pre><code>SplunkError(message: str | Exception)\n</code></pre> <p>             Bases: <code>RuntimeError</code></p> <p>Raised when a Splunk API error occurs</p>"},{"location":"reference/parsedmarc/syslog/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> syslog","text":""},{"location":"reference/parsedmarc/syslog/#parsedmarc.syslog","title":"parsedmarc.syslog","text":""},{"location":"reference/parsedmarc/syslog/#parsedmarc.syslog.SyslogClient","title":"SyslogClient","text":"<pre><code>SyslogClient(server_name: str, server_port: int)\n</code></pre> <p>A client for Syslog</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>The Syslog server</p> required <code>server_port</code> <code>int</code> <p>The Syslog UDP port</p> required"},{"location":"reference/parsedmarc/utils/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> utils","text":""},{"location":"reference/parsedmarc/utils/#parsedmarc.utils","title":"parsedmarc.utils","text":"<p>Utility functions that might be useful for other projects</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.DownloadError","title":"DownloadError","text":"<p>             Bases: <code>RuntimeError</code></p> <p>Raised when an error occurs when downloading a file</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.EmailParserError","title":"EmailParserError","text":"<p>             Bases: <code>RuntimeError</code></p> <p>Raised when an error parsing the email occurs</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.convert_outlook_msg","title":"convert_outlook_msg","text":"<pre><code>convert_outlook_msg(msg_bytes: bytes) -&gt; bytes\n</code></pre> <p>Convert an Outlook MS file to standard RFC 822 format</p> <p>Requires the <code>msgconvert</code> Perl utility to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>msg_bytes</code> <code>bytes</code> <p>the content of the .msg file</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>A RFC 822 string</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.decode_base64","title":"decode_base64","text":"<pre><code>decode_base64(data: str) -&gt; bytes\n</code></pre> <p>Decodes a base64 string, with padding being optional</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>A base64 encoded string</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>The decoded bytes</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.extract_xml","title":"extract_xml","text":"<pre><code>extract_xml(source: str | bytes | BinaryIO) -&gt; str\n</code></pre> <p>Extracts xml from a zip or gzip file at the given path, file-like object, or bytes.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | bytes | BinaryIO</code> <p>A path to a file, a file like object, or bytes</p> required <p>Returns:</p> Type Description <code>str</code> <p>The extracted XML</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.get_base_domain","title":"get_base_domain","text":"<pre><code>get_base_domain(domain: str) -&gt; str\n</code></pre> <p>Get the base domain name for the given domain</p> note <p>Results are based on a list of public domain suffixes at https://publicsuffix.org/list/public_suffix_list.dat.</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>A domain or subdomain</p> required <p>Returns:</p> Type Description <code>str</code> <p>The base domain of the given domain</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.get_filename_safe_string","title":"get_filename_safe_string","text":"<pre><code>get_filename_safe_string(string: str) -&gt; str\n</code></pre> <p>Convert a string to a string that is safe for a filename</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>A string to make safe for a filename</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string safe for a filename</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.get_ip_address_country","title":"get_ip_address_country","text":"<pre><code>get_ip_address_country(\n    ip_address: str, db_path: str | None = None\n) -&gt; str | None\n</code></pre> <p>Get the ISO code for the country associated with the given IPv4 or IPv6 address</p> <p>Parameters:</p> Name Type Description Default <code>ip_address</code> <code>str</code> <p>The IP address to query for</p> required <code>db_path</code> <code>str | None</code> <p>Path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <p>Returns:</p> Type Description <code>str | None</code> <p>And ISO country code associated with the given IP address</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.get_ip_address_info","title":"get_ip_address_info","text":"<pre><code>get_ip_address_info(\n    ip_address: str,\n    ip_db_path: str | None = None,\n    cache: ExpiringDict | None = None,\n    offline: bool = False,\n    nameservers: list[str] | None = None,\n    timeout: float = 2.0,\n) -&gt; dict[str, Any]\n</code></pre> <p>Get reverse DNS and country information for the given IP address</p> <p>Parameters:</p> Name Type Description Default <code>ip_address</code> <code>str</code> <p>The IP address to check</p> required <code>ip_db_path</code> <code>str | None</code> <p>path to a MMDB file from MaxMind or DBIP</p> <code>None</code> <code>cache</code> <code>ExpiringDict | None</code> <p>Cache storage</p> <code>None</code> <code>offline</code> <code>bool</code> <p>Do not make online queries for geolocation or DNS</p> <code>False</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of (<code>ip_address</code>, <code>country</code>, <code>reverse_dns</code>, <code>base_domain</code>)</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.get_reverse_dns","title":"get_reverse_dns","text":"<pre><code>get_reverse_dns(\n    ip_address: str,\n    cache: ExpiringDict | None = None,\n    nameservers: list[str] | None = None,\n    timeout: float = 2.0,\n) -&gt; str | None\n</code></pre> <p>Resolve an IP address to a hostname using a reverse DNS query</p> <p>Parameters:</p> Name Type Description Default <code>ip_address</code> <code>str</code> <p>The IP address to resolve</p> required <code>cache</code> <code>ExpiringDict | None</code> <p>Cache storage</p> <code>None</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Sets the DNS query timeout in seconds</p> <code>2.0</code> <p>Returns:</p> Type Description <code>str | None</code> <p>The reverse DNS hostname (if any)</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.human_timestamp_to_datetime","title":"human_timestamp_to_datetime","text":"<pre><code>human_timestamp_to_datetime(\n    human_timestamp: str, to_utc: bool = False\n) -&gt; datetime\n</code></pre> <p>Converts a human-readable timestamp into a Python <code>datetime</code> object</p> <p>Parameters:</p> Name Type Description Default <code>human_timestamp</code> <code>str</code> <p>A timestamp string</p> required <code>to_utc</code> <code>bool</code> <p>Convert the timestamp to UTC</p> <code>False</code> <p>Returns:</p> Type Description <code>datetime</code> <p>The converted timestamp</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.human_timestamp_to_timestamp","title":"human_timestamp_to_timestamp","text":"<pre><code>human_timestamp_to_timestamp(human_timestamp: str) -&gt; float\n</code></pre> <p>Converts a human-readable timestamp into a UNIX timestamp</p> <p>Parameters:</p> Name Type Description Default <code>human_timestamp</code> <code>str</code> <p>A timestamp in <code>YYYY-MM-DD HH:MM:SS</code> format</p> required <p>Returns:</p> Type Description <code>float</code> <p>The converted timestamp</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.is_mbox","title":"is_mbox","text":"<pre><code>is_mbox(path: str) -&gt; bool\n</code></pre> <p>Checks if the given content is an MBOX mailbox file</p> <p>Returns:</p> Type Description <code>bool</code> <p>If the file is an MBOX mailbox file</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.is_outlook_msg","title":"is_outlook_msg","text":"<pre><code>is_outlook_msg(content: Any) -&gt; bool\n</code></pre> <p>Checks if the given content is an Outlook msg OLE/MSG file</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>Any</code> <p>Content to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>If the file is an Outlook MSG file</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.parse_email","title":"parse_email","text":"<pre><code>parse_email(\n    data: bytes | str,\n    strip_attachment_payloads: bool = False,\n) -&gt; dict[str, Any]\n</code></pre> <p>A simplified email parser</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes | str</code> <p>The RFC 822 message string, or MSG binary</p> required <code>strip_attachment_payloads</code> <code>bool</code> <p>Remove attachment payloads</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Parsed email data</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.parse_email_address","title":"parse_email_address","text":"<pre><code>parse_email_address(\n    original_address: str,\n) -&gt; dict[str, Any]\n</code></pre> <p>Parse an email into parts</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.query_dns","title":"query_dns","text":"<pre><code>query_dns(\n    domain: str,\n    record_type: str,\n    cache: ExpiringDict | None = None,\n    nameservers: list[str] | None = None,\n    timeout: float = 2.0,\n) -&gt; list[str]\n</code></pre> <p>Make a DNS query</p> <p>Parameters:</p> Name Type Description Default <code>domain</code> <code>str</code> <p>The domain or subdomain to query about</p> required <code>record_type</code> <code>str</code> <p>The record type to query for</p> required <code>cache</code> <code>ExpiringDict | None</code> <p>Cache storage</p> <code>None</code> <code>nameservers</code> <code>list[str] | None</code> <p>A list of one or more nameservers to use (Cloudflare's public DNS resolvers by default)</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Sets the DNS timeout in seconds</p> <code>2.0</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of answers</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.timestamp_to_datetime","title":"timestamp_to_datetime","text":"<pre><code>timestamp_to_datetime(timestamp: int) -&gt; datetime\n</code></pre> <p>Converts a UNIX/DMARC timestamp to a Python <code>datetime</code> object</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>int</code> <p>The timestamp</p> required <p>Returns:</p> Type Description <code>datetime</code> <p>The converted timestamp as a Python <code>datetime</code> object</p>"},{"location":"reference/parsedmarc/utils/#parsedmarc.utils.timestamp_to_human","title":"timestamp_to_human","text":"<pre><code>timestamp_to_human(timestamp: int) -&gt; str\n</code></pre> <p>Converts a UNIX/DMARC timestamp to a human-readable string</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>int</code> <p>The timestamp</p> required <p>Returns:</p> Type Description <code>str</code> <p>The converted timestamp in <code>YYYY-MM-DD HH:MM:SS</code> format</p>"},{"location":"reference/parsedmarc/mail/","title":"Index","text":""},{"location":"reference/parsedmarc/mail/#parsedmarc.mail","title":"parsedmarc.mail","text":""},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.GmailConnection","title":"GmailConnection","text":"<pre><code>GmailConnection(\n    token_file: str,\n    credentials_file: str,\n    scopes: list[str],\n    include_spam_trash: bool,\n    reports_folder: str,\n    oauth2_port: int,\n)\n</code></pre> <p>             Bases: <code>MailboxConnection</code></p> <p>MailboxConnection for Google accounts using the Google API.</p> <p>This will support both Gmail and Google Workspace accounts.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> required <code>credentials_file</code> <code>str</code> required <code>scopes</code> <code>list[str]</code> required <code>include_spam_trash</code> <code>bool</code> required <code>reports_folder</code> <code>str</code> required <code>oauth2_port</code> <code>int</code> required"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.GmailConnection.watch","title":"watch","text":"<pre><code>watch(check_callback, check_timeout) -&gt; None\n</code></pre> <p>Checks the mailbox for new messages every n seconds</p>"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.IMAPConnection","title":"IMAPConnection","text":"<pre><code>IMAPConnection(\n    host: str | None = None,\n    user: str | None = None,\n    password: str | None = None,\n    port: int | None = None,\n    ssl: bool = True,\n    verify: bool = True,\n    timeout: int = 30,\n    max_retries: int = 4,\n)\n</code></pre> <p>             Bases: <code>MailboxConnection</code></p> <p>MailboxConnection for connecting to a mailbox via IMAP.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str | None</code> <p>Host to connect to</p> <code>None</code> <code>user</code> <code>str | None</code> <code>None</code> <code>password</code> <code>str | None</code> <code>None</code> <code>port</code> <code>int | None</code> <p>Port to connect to</p> <code>None</code> <code>ssl</code> <code>bool</code> <p>Use SSL/TLS</p> <code>True</code> <code>verify</code> <code>bool</code> <p>Verify the SSL/TLS certification</p> <code>True</code> <code>timeout</code> <code>int</code> <code>30</code> <code>max_retries</code> <code>int</code> <code>4</code>"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.IMAPConnection.watch","title":"watch","text":"<pre><code>watch(check_callback, check_timeout)\n</code></pre> <p>Use an IDLE IMAP connection to parse incoming emails, and pass the results to a callback function</p>"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.MSGraphConnection","title":"MSGraphConnection","text":"<pre><code>MSGraphConnection(\n    auth_method: str,\n    mailbox: str,\n    client_id: str,\n    client_secret: str,\n    username: str,\n    password: str,\n    tenant_id: str,\n    token_file: str,\n    allow_unencrypted_storage: bool,\n)\n</code></pre> <p>             Bases: <code>MailboxConnection</code></p> <p>MailboxConnection to a Microsoft account via the Micorsoft Graph API</p> <p>Parameters:</p> Name Type Description Default <code>auth_method</code> <code>str</code> required <code>mailbox</code> <code>str</code> required <code>client_id</code> <code>str</code> required <code>client_secret</code> <code>str</code> required <code>username</code> <code>str</code> required <code>password</code> <code>str</code> required <code>tenant_id</code> <code>str</code> required <code>token_file</code> <code>str</code> required <code>allow_unencrypted_storage</code> <code>bool</code> required"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.MSGraphConnection.fetch_messages","title":"fetch_messages","text":"<pre><code>fetch_messages(reports_folder: str, **kwargs) -&gt; list[str]\n</code></pre> <p>Returns a list of message UIDs in the specified folder</p>"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.MSGraphConnection.mark_message_read","title":"mark_message_read","text":"<pre><code>mark_message_read(message_id: str)\n</code></pre> <p>Marks a message as read</p>"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.MSGraphConnection.watch","title":"watch","text":"<pre><code>watch(check_callback, check_timeout)\n</code></pre> <p>Checks the mailbox for new messages every n seconds</p>"},{"location":"reference/parsedmarc/mail/#parsedmarc.mail.MailboxConnection","title":"MailboxConnection","text":"<p>             Bases: <code>ABC</code></p> <p>Interface for a mailbox connection</p>"},{"location":"reference/parsedmarc/mail/gmail/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> gmail","text":""},{"location":"reference/parsedmarc/mail/gmail/#parsedmarc.mail.gmail","title":"parsedmarc.mail.gmail","text":""},{"location":"reference/parsedmarc/mail/gmail/#parsedmarc.mail.gmail.GmailConnection","title":"GmailConnection","text":"<pre><code>GmailConnection(\n    token_file: str,\n    credentials_file: str,\n    scopes: list[str],\n    include_spam_trash: bool,\n    reports_folder: str,\n    oauth2_port: int,\n)\n</code></pre> <p>             Bases: <code>MailboxConnection</code></p> <p>MailboxConnection for Google accounts using the Google API.</p> <p>This will support both Gmail and Google Workspace accounts.</p> <p>Parameters:</p> Name Type Description Default <code>token_file</code> <code>str</code> required <code>credentials_file</code> <code>str</code> required <code>scopes</code> <code>list[str]</code> required <code>include_spam_trash</code> <code>bool</code> required <code>reports_folder</code> <code>str</code> required <code>oauth2_port</code> <code>int</code> required"},{"location":"reference/parsedmarc/mail/gmail/#parsedmarc.mail.gmail.GmailConnection.watch","title":"watch","text":"<pre><code>watch(check_callback, check_timeout) -&gt; None\n</code></pre> <p>Checks the mailbox for new messages every n seconds</p>"},{"location":"reference/parsedmarc/mail/graph/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> graph","text":""},{"location":"reference/parsedmarc/mail/graph/#parsedmarc.mail.graph","title":"parsedmarc.mail.graph","text":""},{"location":"reference/parsedmarc/mail/graph/#parsedmarc.mail.graph.MSGraphConnection","title":"MSGraphConnection","text":"<pre><code>MSGraphConnection(\n    auth_method: str,\n    mailbox: str,\n    client_id: str,\n    client_secret: str,\n    username: str,\n    password: str,\n    tenant_id: str,\n    token_file: str,\n    allow_unencrypted_storage: bool,\n)\n</code></pre> <p>             Bases: <code>MailboxConnection</code></p> <p>MailboxConnection to a Microsoft account via the Micorsoft Graph API</p> <p>Parameters:</p> Name Type Description Default <code>auth_method</code> <code>str</code> required <code>mailbox</code> <code>str</code> required <code>client_id</code> <code>str</code> required <code>client_secret</code> <code>str</code> required <code>username</code> <code>str</code> required <code>password</code> <code>str</code> required <code>tenant_id</code> <code>str</code> required <code>token_file</code> <code>str</code> required <code>allow_unencrypted_storage</code> <code>bool</code> required"},{"location":"reference/parsedmarc/mail/graph/#parsedmarc.mail.graph.MSGraphConnection.fetch_messages","title":"fetch_messages","text":"<pre><code>fetch_messages(reports_folder: str, **kwargs) -&gt; list[str]\n</code></pre> <p>Returns a list of message UIDs in the specified folder</p>"},{"location":"reference/parsedmarc/mail/graph/#parsedmarc.mail.graph.MSGraphConnection.mark_message_read","title":"mark_message_read","text":"<pre><code>mark_message_read(message_id: str)\n</code></pre> <p>Marks a message as read</p>"},{"location":"reference/parsedmarc/mail/graph/#parsedmarc.mail.graph.MSGraphConnection.watch","title":"watch","text":"<pre><code>watch(check_callback, check_timeout)\n</code></pre> <p>Checks the mailbox for new messages every n seconds</p>"},{"location":"reference/parsedmarc/mail/imap/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> imap","text":""},{"location":"reference/parsedmarc/mail/imap/#parsedmarc.mail.imap","title":"parsedmarc.mail.imap","text":""},{"location":"reference/parsedmarc/mail/imap/#parsedmarc.mail.imap.IMAPConnection","title":"IMAPConnection","text":"<pre><code>IMAPConnection(\n    host: str | None = None,\n    user: str | None = None,\n    password: str | None = None,\n    port: int | None = None,\n    ssl: bool = True,\n    verify: bool = True,\n    timeout: int = 30,\n    max_retries: int = 4,\n)\n</code></pre> <p>             Bases: <code>MailboxConnection</code></p> <p>MailboxConnection for connecting to a mailbox via IMAP.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str | None</code> <p>Host to connect to</p> <code>None</code> <code>user</code> <code>str | None</code> <code>None</code> <code>password</code> <code>str | None</code> <code>None</code> <code>port</code> <code>int | None</code> <p>Port to connect to</p> <code>None</code> <code>ssl</code> <code>bool</code> <p>Use SSL/TLS</p> <code>True</code> <code>verify</code> <code>bool</code> <p>Verify the SSL/TLS certification</p> <code>True</code> <code>timeout</code> <code>int</code> <code>30</code> <code>max_retries</code> <code>int</code> <code>4</code>"},{"location":"reference/parsedmarc/mail/imap/#parsedmarc.mail.imap.IMAPConnection.watch","title":"watch","text":"<pre><code>watch(check_callback, check_timeout)\n</code></pre> <p>Use an IDLE IMAP connection to parse incoming emails, and pass the results to a callback function</p>"},{"location":"reference/parsedmarc/mail/mailbox_connection/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> mailbox_connection","text":""},{"location":"reference/parsedmarc/mail/mailbox_connection/#parsedmarc.mail.mailbox_connection","title":"parsedmarc.mail.mailbox_connection","text":""},{"location":"reference/parsedmarc/mail/mailbox_connection/#parsedmarc.mail.mailbox_connection.MailboxConnection","title":"MailboxConnection","text":"<p>             Bases: <code>ABC</code></p> <p>Interface for a mailbox connection</p>"},{"location":"reference/parsedmarc/resources/","title":"Index","text":""},{"location":"reference/parsedmarc/resources/#parsedmarc.resources","title":"parsedmarc.resources","text":""},{"location":"reference/parsedmarc/resources/dbip/","title":"<code class=\"doc-symbol doc-symbol-nav doc-symbol-module\"></code> dbip","text":""},{"location":"reference/parsedmarc/resources/dbip/#parsedmarc.resources.dbip","title":"parsedmarc.resources.dbip","text":""}]}